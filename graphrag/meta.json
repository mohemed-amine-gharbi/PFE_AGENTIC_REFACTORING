[
  {
    "id": "adcd2162050c6c84",
    "text": "# C Complexity Reduction Patterns\n\n## Goal\nReduce cyclomatic/cognitive complexity in C code without changing behavior.\n\n## Common Smells\n- Deeply nested `if/else`\n- Long conditional chains\n- Functions mixing validation + parsing + processing + I/O\n- Repeated conditional logic\n- Excessive nested loops\n- Large `switch` blocks with duplicated branches\n\n## Safe Complexity Reduction Patterns\n\n### 1. Guard Clauses (Early Return)\nReplace nesting with early exits when semantics are preserved.\n\n#### Before\n```c\nif (user != NULL) {\n    if (user->is_active) {\n        process(user);\n    }\n}\nif (user == NULL) return;\nif (!user->is_active) return;\nprocess(user);\n\n### 3. Split Large Functions by Responsibility\nSplit into:\n- validation\n- parsing\n- computation\n- output / persistence\n\n### 4. Simplify Loop Bodies\n- use `continue` for guard checks\n- extract heavy loop logic into helper functions\n\n### 5. Replace Duplicated Branch Logic with Shared Helper\nOnly if side effects and execution order remain identical.\n\n## Semantic Preservation Constraints\n- do not change return values\n- do not change side effects or their order\n- do not change pointer mutation timing\n- do not change memory ownership semantic",
    "source": "knowledge/c/complexity_patterns.md"
  },
  {
    "id": "ada7c670032b878f",
    "text": "not change return values\n- do not change side effects or their order\n- do not change pointer mutation timing\n- do not change memory ownership semantics\n- do not change error codes / errno behavior\n- do not change public function signatures unless explicitly requested\n\n## C-Specific Sensitive Cases\n- NULL checks and dereference order\n- pointer aliasing\n- buffer sizes and bounds\n- signed/unsigned behavior\n- integer overflow/underflow behavior\n- `malloc/free` ownership and lifetime\n- `goto cleanup` error handling patterns\n- macro side effects (evaluate arguments carefully)\n\n## Expected Agent Output\n- list detected complexity smells\n- propose a targeted refactor\n- explain why semantics are preserved",
    "source": "knowledge/c/complexity_patterns.md"
  },
  {
    "id": "d98cf080c00c1f6e",
    "text": "# C Duplication Refactoring Patterns\n\n## Goal\nReduce duplicated C code safely without introducing unnecessary abstraction.\n\n## Common Duplication in C\n- repeated input validation\n- repeated error handling / cleanup\n- repeated struct initialization\n- repeated loops over arrays\n- repeated parsing logic\n- repeated logging / error messages\n\n## Safe Patterns\n\n### 1. Extract Static Helper Function\nFactor repeated logic into a `static` helper when:\n- inputs/outputs are explicit\n- side effects are clear\n- memory ownership remains unchanged\n\n### 2. Consolidate Repeated Cleanup\nCentralize cleanup using:\n- helper function\n- or a controlled `goto cleanup` pattern\n\n### 3. Reuse Validation Functions\nExamples:\n- `validate_input(...)`\n- `validate_config(...)`\n\n### 4. Shared Initialization Functions\nFor repeated initialization of structs:\n- `init_request(...)`\n- `reset_buffer(...)`\n\n### 5. Extract Repeated Constants/Messages\nMove repeated literals to constants/macros only if it improves clarity.\n\n## Anti-Patterns\n- over-generalizing with complex macros\n- introducing function pointers just to remove a few lines\n- merging blocks that look similar but differ in resource ownership or side effects\n\n## S",
    "source": "knowledge/c/duplication_patterns.md"
  },
  {
    "id": "158a6b9d356fcf31",
    "text": "s\n- introducing function pointers just to remove a few lines\n- merging blocks that look similar but differ in resource ownership or side effects\n\n## Safety Checks Before Refactoring\n- same return code?\n- same errno / error state?\n- same memory allocation/free behavior?\n- same execution order?\n- same pointer writes?",
    "source": "knowledge/c/duplication_patterns.md"
  },
  {
    "id": "8d78840c4de9f566",
    "text": "# C Include Cleanup Patterns\n\n## Goal\nClean C includes safely.\n\n## Typical Tasks\n- remove unused `#include`\n- remove duplicate includes\n- keep required standard/library/project headers\n- preserve include order conventions if the project has one\n\n## Safe Rules\n- do not remove headers required transitively only if the file directly depends on macros/types from them\n- be careful with platform-specific headers\n- preserve include guards behavior (in headers)\n- do not change macro definitions while cleaning includes\n\n## C-Specific Cases\n\n### 1. Type Definitions\nA header may be required for:\n- `size_t`\n- `uint32_t`\n- `FILE`\n- `bool`\n- struct declarations\n- enums / typedefs\n\n### 2. Macros and Inline Functions\nAn include may look unused but provides:\n- macros\n- static inline helpers\n- compile-time constants\n\n### 3. Conditional Compilation\nHeaders inside `#ifdef` / `#if` blocks may be necessary on some platforms.\n\n## Style (Project-Dependent)\nCommon style:\n1. local header (`\"module.h\"`)\n2. project headers\n3. standard library headers (`<stdio.h>`, `<stdlib.h>`, ...)\n4. third-party headers\n\n## Expected Agent Output\n- list unused/duplicate includes\n- return full code with cleaned includes\n- pre",
    "source": "knowledge/c/import_patterns.md"
  },
  {
    "id": "3ba03240a91d79e4",
    "text": "`, `<stdlib.h>`, ...)\n4. third-party headers\n\n## Expected Agent Output\n- list unused/duplicate includes\n- return full code with cleaned includes\n- preserve functionality and portability assumptions",
    "source": "knowledge/c/import_patterns.md"
  },
  {
    "id": "3bf4da08fe70c342",
    "text": "# C Long Function Refactoring Patterns\n\n## Goal\nSplit overly long C functions into smaller readable/testable helpers.\n\n## Smells\n- function > 30–60 lines (heuristic)\n- validation + parsing + business logic + I/O in one function\n- too many temporary variables\n- deeply nested loops/conditionals\n- repeated cleanup/error paths\n\n## Safe Patterns\n\n### 1. Split by Responsibility\nCommon split:\n- `validate_input(...)`\n- `parse_request(...)`\n- `compute_result(...)`\n- `write_output(...)`\n- `cleanup_resources(...)`\n\n### 2. Extract Large Conditional Blocks\nIf an `if` branch is long, extract to a helper with explicit parameters.\n\n### 3. Extract Loop Body Processing\nKeep loop skeleton in parent function; move heavy work to helper.\n\n```c\nfor (size_t i = 0; i < count; ++i) {\n    process_item(&items[i], ctx);\n}\n4. Standardize Error Handling\n\nIf many error exits exist, use one cleanup path (goto cleanup) only if already idiomatic in the project.\n\nC Precautions\n\npreserve resource cleanup order\n\npreserve allocation/free ownership\n\npreserve return codes and errno behavior\n\npreserve pointer aliasing assumptions\n\npreserve global/static state mutations\n\ndo not hide important side effects in macros\n\nHeurist",
    "source": "knowledge/c/long_function_patterns.md"
  },
  {
    "id": "e200a9caf3179e8a",
    "text": "d errno behavior\n\npreserve pointer aliasing assumptions\n\npreserve global/static state mutations\n\ndo not hide important side effects in macros\n\nHeuristic\n\nExtract only when clarity improves and ownership/side-effects remain obvious.",
    "source": "knowledge/c/long_function_patterns.md"
  },
  {
    "id": "fd6183265f79094a",
    "text": "# C Rename Patterns (Safe Renaming)\n\n## Goal\nImprove readability through safe renaming in C code.\n\n## Safe Targets (Priority)\n- local variables (`x`, `tmp`, `res`, `buf`)\n- loop counters when ambiguous (`i`, `j`) in complex loops\n- private/static helper function names\n- unclear parameters in internal functions\n\n## Sensitive Targets (Avoid Without Strong Context)\n- public API function names\n- struct fields used across many modules\n- macro names used externally\n- symbols referenced in linker scripts/build scripts\n- callback names tied to frameworks/libraries\n\n## C Naming Best Practices\n- functions/variables: `snake_case`\n- macros/constants: `UPPER_SNAKE_CASE`\n- booleans: `is_valid`, `has_error`, `should_retry`\n- pointers may use suffixes/prefixes only if project style uses them (`out_buf`, `input_ptr`)\n\n## Examples\n- `x` -> `item_count`\n- `tmp` -> `temp_buffer`\n- `res` -> `status_code`\n- `p` -> `user_ptr`\n- `n` -> `buffer_length`\n\n## Safety Rules\n- do not rename public API symbols unless explicitly requested\n- preserve semantics and storage duration meaning\n- keep consistency with project naming conventions\n- avoid renaming macros unless usage is fully controlled\n\n## Expected Agent O",
    "source": "knowledge/c/rename_patterns.md"
  },
  {
    "id": "7d4712936b8ce4cf",
    "text": "rage duration meaning\n- keep consistency with project naming conventions\n- avoid renaming macros unless usage is fully controlled\n\n## Expected Agent Output\n- identify unclear names and explain why they reduce readability\n- propose safer, meaningful renamings\n- avoid renaming public/external symbols unless explicitly requested\n- return full refactored code with naming consistency",
    "source": "knowledge/c/rename_patterns.md"
  },
  {
    "id": "114d9b4d9beccf1b",
    "text": "# Java Complexity Reduction Patterns\n\n## Goal\nReduce cyclomatic/cognitive complexity in Java code without changing behavior.\n\n## Common Smells\n- Deeply nested `if/else`\n- Long conditional chains\n- Methods mixing validation + transformation + I/O\n- Repeated conditional logic\n- Excessive nested loops\n- Large `try/catch` blocks mixed with business logic\n\n## Safe Complexity Reduction Patterns\n\n### 1. Guard Clauses (Early Return)\nReplace nesting with early exits when semantics are preserved.\n\n#### Before\n```java\nif (user != null) {\n    if (user.isActive()) {\n        process(user);\n    }\n}\n#### After\n```java\nif (user == null) return;\nif (!user.isActive()) return;\nprocess(user);\n\nprivate boolean isEligible(User user) {\n    return user != null && user.isActive() && !user.isBlocked();\n}",
    "source": "knowledge/java/complexity_patterns.md"
  },
  {
    "id": "23cbfa0921fee4fb",
    "text": "# Java Duplication Refactoring Patterns\n\n## Goal\nReduce duplicated Java code without over-abstraction.\n\n## Common Duplication in Java\n- repeated validation blocks across methods\n- repeated DTO <-> Entity mapping\n- repeated `try/catch` blocks\n- repeated object construction\n- repeated filtering/formatting loops\n- repeated repository/service calls with minor variations\n\n## Safe Patterns\n\n### 1. Extract Private Method\nFactor repeated blocks into a private method if:\n- inputs/outputs are clear\n- no hidden implicit dependencies\n\n### 2. Local Template (No Over-Engineering)\nIf two methods share the same structure with small variations:\n- extract common flow\n- pass variation via parameter/helper method\n\n### 3. Centralize Validation\nCreate methods like:\n- `validateProduct(...)`\n- `validateRequest(...)`\n\n### 4. Mapping Utilities (If Duplication Is Real)\nExamples:\n- `toDto(entity)`\n- `updateEntityFromDto(dto, entity)`\n\nBe careful:\n- do not break JPA/framework annotations\n- do not move logic that depends on transaction/session context\n\n### 5. Extract Repeated Messages to Constants\nCentralize repeated strings/error messages.\n\n## Anti-Patterns\n- creating a complex class hierarchy to remove a few ",
    "source": "knowledge/java/duplication_patterns.md"
  },
  {
    "id": "8b798d0a1788f765",
    "text": "act Repeated Messages to Constants\nCentralize repeated strings/error messages.\n\n## Anti-Patterns\n- creating a complex class hierarchy to remove a few lines\n- introducing reflection/generics unnecessarily\n- merging code that looks similar but is not semantically identical\n\n## Safety Checks Before Refactoring\n- same exceptions?\n- same side effects?\n- same execution order?\n- same transaction/session context assumptions?",
    "source": "knowledge/java/duplication_patterns.md"
  },
  {
    "id": "260704708821fa04",
    "text": "# Java Import Cleanup Patterns\n\n## Goal\nClean Java imports safely.\n\n## Typical Tasks\n- remove unused imports\n- remove duplicate imports\n- organize imports (based on project style)\n- avoid wildcard imports if project conventions forbid them\n\n## Safe Rules\n- do not remove imports used indirectly by annotations/references\n- be careful with name conflicts (`Date`, `List`, etc.)\n- preserve static imports when used (`import static ...`)\n- do not introduce wildcard imports unless explicitly allowed\n\n## Java-Specific Cases\n\n### 1. Annotations\nSome annotations may look “invisible” but are critical:\n- `@Transactional`\n- `@Entity`\n- `@Autowired`\n- `@JsonProperty`\n- etc.\n\n### 2. Inner/Nested Classes\nAn import may be required for a nested type reference.\n\n### 3. Lombok\nLombok imports (`@Data`, `@Builder`, etc.) can be essential.\n\n### 4. Static Imports\nDo not remove without verifying usage:\n```java\nimport static java.util.Objects.requireNonNull;",
    "source": "knowledge/java/import_patterns.md"
  },
  {
    "id": "4d3aee97359842b3",
    "text": "# Java Long Function Refactoring Patterns\n\n## Goal\nSplit overly long methods into smaller, readable, testable methods.\n\n## Smells\n- method longer than ~30–50 lines (heuristic)\n- validation + transformation + DB + logging + notification in one method\n- too many temporary variables\n- repeated conditional blocks\n- comments like \"Step 1 / Step 2 / Step 3\" (often signals extractable methods)\n\n## Safe Patterns\n\n### 1. Split by Responsibility\nCommon sequence:\n- `validateRequest(...)`\n- `loadEntity(...)`\n- `applyBusinessRules(...)`\n- `saveEntity(...)`\n- `buildResponse(...)`\n\n### 2. Extract Long Conditional Blocks\nIf an `if` block is large, extract it to a dedicated method.\n\n### 3. Reduce Loop Body Length\nExtract item processing:\n```java\nfor (Order order : orders) {\n    processOrder(order);\n}",
    "source": "knowledge/java/long_function_patterns.md"
  },
  {
    "id": "949aab6532cbccf2",
    "text": "# Java Rename Patterns (Safe Renaming)\n\n## Goal\nImprove readability through safe renaming (local variables, parameters, private methods).\n\n## Safe Targets (Priority)\n- local variables (`x`, `tmp`, `res`)\n- unclear internal parameters\n- ambiguous loop variables\n- private methods with vague names\n\n## Sensitive Targets (Avoid Without Strong Context)\n- public methods (API contract)\n- fields exposed via frameworks/serialization\n- names used by reflection\n- JPA/Hibernate names with implicit mapping assumptions\n- JSON/XML mapped names without explicit annotations\n\n## Java Naming Best Practices\n- classes: `PascalCase`\n- methods/variables: `camelCase`\n- constants: `UPPER_SNAKE_CASE`\n- booleans: `isActive`, `hasAccess`, `canEdit`, `shouldRetry`\n\n## Examples\n- `x` -> `userCount`\n- `tmp` -> `formattedMessage`\n- `res` -> `validationResult`\n- `l` -> `lineItems`\n- `f` -> `inputFile`\n\n## Safety Rules\n- do not change the meaning of names\n- avoid mass renaming without clear benefit\n- keep consistency with existing file/project conventions\n- preserve public signatures unless explicitly requested",
    "source": "knowledge/java/rename_patterns.md"
  },
  {
    "id": "dc59a7cb0927482a",
    "text": "blic signatures unless explicitly requested",
    "source": "knowledge/java/rename_patterns.md"
  },
  {
    "id": "d2c74f484bc5ba0a",
    "text": "# JavaScript Complexity Reduction Patterns\n\n## Goal\nReduce cyclomatic/cognitive complexity in JavaScript code without changing behavior.\n\n## Common Smells\n- Deeply nested `if/else`\n- Long conditional chains\n- Functions mixing validation + transformation + I/O\n- Repeated conditional logic\n- Excessive nested loops\n- Large `try/catch` blocks mixed with business logic\n- Callback pyramids / deeply nested async code\n\n## Safe Complexity Reduction Patterns\n\n### 1. Guard Clauses (Early Return)\nReplace nesting with early exits when semantics are preserved.\n\n#### Before\n```javascript\nif (user) {\n  if (user.isActive) {\n    processUser(user);\n  }\n}\nAfter\nif (!user) return;\nif (!user.isActive) return;\nprocessUser(user);\n### 2. Extract Complex Conditions into Helper Functions\n\nImproves readability while preserving logic\nfunction isEligible(user) {\n  return user && user.isActive && !user.isBlocked;\n}\n### 3. Split Large Functions by Responsibility\nSplit into:\n- validation\n- parsing / normalization\n- computation\n- persistence / API calls\n- presentation formatting\n\n### 4. Simplify Loop Bodies\n- use `continue` for guard checks\n- extract heavy loop logic into helper functions\n- prefer clear iteration o",
    "source": "knowledge/javascript/complexity_patterns.md"
  },
  {
    "id": "9b8b2f4e9b133d66",
    "text": " formatting\n\n### 4. Simplify Loop Bodies\n- use `continue` for guard checks\n- extract heavy loop logic into helper functions\n- prefer clear iteration over nested branching\n\n### 5. Replace Duplicated Branch Logic with Shared Helper\nOnly if side effects and execution order remain identical.\n\n### 6. Flatten Async Control Flow\n- prefer `async/await` over deeply nested `.then()`\n- separate error handling from core logic when possible\n- preserve `await` order and side effects\n\n## Semantic Preservation Constraints\n- do not change return values\n- do not change side effects or their order\n- do not change sync vs async behavior\n- do not change thrown errors / error propagation\n- do not change public function signatures unless explicitly requested\n- preserve mutation timing and object reference behavior\n\n## JavaScript-Specific Sensitive Cases\n- truthy/falsy behavior\n- optional chaining / nullish coalescing semantics\n- async/await timing and promise resolution order\n- object/array mutation by reference\n- `this` binding\n- closure capture behavior\n- short-circuit evaluation side effects\n- loose vs strict equality (`==` vs `===`)\n\n## Expected Agent Output\n- list detected complexity smells\n- propos",
    "source": "knowledge/javascript/complexity_patterns.md"
  },
  {
    "id": "51d5b8fb24e0380b",
    "text": " short-circuit evaluation side effects\n- loose vs strict equality (`==` vs `===`)\n\n## Expected Agent Output\n- list detected complexity smells\n- propose a targeted refactor\n- explain why semantics are preserved",
    "source": "knowledge/javascript/complexity_patterns.md"
  },
  {
    "id": "3f34f195d92e227b",
    "text": "# JavaScript Duplication Refactoring Patterns\n\n## Goal\nReduce duplicated JavaScript code safely while preserving behavior.\n\n## Common Duplication\n- repeated validation checks\n- repeated object mapping / formatting\n- repeated API response handling\n- repeated try/catch + logging blocks\n- repeated array transformations\n- repeated DOM update logic\n\n## Safe Patterns\n\n### 1. Extract Helper Functions\nCreate small pure helpers for repeated logic when possible.\n\n### 2. Reuse Validation Utilities\nExamples:\n- `validateUser(user)`\n- `validatePayload(payload)`\n\n### 3. Consolidate Response Formatting\nCentralize repeated object shaping / DTO mapping.\n\n### 4. Shared Error Handling (Carefully)\nExtract repeated error logging/formatting only if error propagation remains the same.\n\n### 5. Reuse Configuration Objects\nExtract repeated options/constants (timeouts, headers, flags) when stable.\n\n## Anti-Patterns\n- over-abstracting tiny differences\n- creating generic helpers that reduce readability\n- merging blocks with different side effects\n- hiding control flow in utility functions unnecessarily\n\n## Safety Checks Before Refactoring\n- same return values?\n- same thrown errors?\n- same async behavior (`await",
    "source": "knowledge/javascript/duplication_patterns.md"
  },
  {
    "id": "03a772188f1b80f5",
    "text": "flow in utility functions unnecessarily\n\n## Safety Checks Before Refactoring\n- same return values?\n- same thrown errors?\n- same async behavior (`await` order)?\n- same object mutation behavior?\n- same logging and side effects?",
    "source": "knowledge/javascript/duplication_patterns.md"
  },
  {
    "id": "074bc08ddb0c249e",
    "text": "# JavaScript Import Cleanup Patterns\n\n## Goal\nClean JavaScript imports safely.\n\n## Typical Tasks\n- remove unused imports\n- remove duplicate imports\n- normalize import grouping/order (if project style requires it)\n- keep side-effect imports that are required\n\n## Safe Rules\n- do not remove side-effect imports (e.g. `import \"./setup\";`) unless confirmed unused\n- preserve runtime-required imports even if statically hard to detect\n- preserve import order if side effects depend on order\n- do not rewrite module format (ESM/CommonJS) unless explicitly requested\n\n## JavaScript-Specific Cases\n\n### 1. Side-Effect Imports\nThese may appear unused but are required:\n- polyfills\n- global setup\n- CSS imports in frontend apps\n- monkey patches / instrumentation\n\n### 2. Named vs Default Imports\nBe careful when changing syntax:\n- `import x from \"m\"`\n- `import { x } from \"m\"`\n\n### 3. Type-Only Imports (TS projects nearby)\nIn mixed JS/TS repos, avoid assumptions when files interact.\n\n## Style (Project-Dependent)\nCommon grouping:\n1. built-in / platform modules\n2. third-party packages\n3. internal absolute imports\n4. relative imports\n\n## Expected Agent Output\n- list unused/duplicate imports\n- return full co",
    "source": "knowledge/javascript/import_patterns.md"
  },
  {
    "id": "2ce51275c51bc56a",
    "text": "es\n2. third-party packages\n3. internal absolute imports\n4. relative imports\n\n## Expected Agent Output\n- list unused/duplicate imports\n- return full code with cleaned imports\n- preserve functionality and side effects",
    "source": "knowledge/javascript/import_patterns.md"
  },
  {
    "id": "7071105c9bdc6805",
    "text": "# JavaScript Long Function Refactoring Patterns\n\n## Goal\nSplit overly long JavaScript functions into smaller, readable, testable helpers.\n\n## Smells\n- function > 30–60 lines (heuristic)\n- validation + transformation + persistence + UI updates in one function\n- too many temporary variables\n- deeply nested conditionals\n- repeated try/catch or error handling\n- mixed sync and async concerns in one block\n\n## Safe Patterns\n\n### 1. Split by Responsibility\nCommon split:\n- `validateInput(...)`\n- `normalizeInput(...)`\n- `computeResult(...)`\n- `saveResult(...)`\n- `formatResponse(...)`\n\n### 2. Extract Large Conditional Blocks\nIf a branch is long, extract it to a helper with explicit inputs.\n\n### 3. Extract Loop Body Processing\nKeep iteration in parent function, move heavy logic to helper.\n\n```javascript\nfor (const item of items) {\n  processItem(item, context);\n}\n### 4. Isolate Error Handling\nExtract repetitive error formatting/logging, but preserve throw/return behavior.\n\n### 5. Separate Async Steps Clearly\nBreak large async functions into small awaited steps while preserving order.\n\n## JavaScript Precautions\n- preserve `await` order\n- preserve thrown errors and rejected promises\n- preserve ob",
    "source": "knowledge/javascript/long_function_patterns.md"
  },
  {
    "id": "019bed1d31629935",
    "text": "awaited steps while preserving order.\n\n## JavaScript Precautions\n- preserve `await` order\n- preserve thrown errors and rejected promises\n- preserve object mutation/reference behavior\n- preserve `this` context where relevant\n- preserve event handler side effects and timing\n\n## Heuristic\nExtract only when readability improves and side effects remain obvious.\n",
    "source": "knowledge/javascript/long_function_patterns.md"
  },
  {
    "id": "b7ad13cc83a6a30d",
    "text": "# JavaScript Rename Patterns (Safe Renaming)\n\n## Goal\nImprove readability through safe renaming in JavaScript code.\n\n## Safe Targets (Priority)\n- local variables (`x`, `tmp`, `res`, `data`)\n- loop variables when ambiguous\n- internal/private helper function names\n- unclear parameters in internal functions\n- callback parameters (`e`, `d`, `r`) when context is unclear\n\n## Sensitive Targets (Avoid Without Strong Context)\n- exported/public API names\n- object keys used externally (API/contracts)\n- framework lifecycle method names\n- event names / route names\n- global variables used across files\n- destructured property names tied to external payloads\n\n## JavaScript Naming Best Practices\n- variables/functions: `camelCase`\n- constants: `UPPER_SNAKE_CASE` (project-dependent)\n- booleans: `isValid`, `hasError`, `shouldRetry`\n- collections: plural names (`users`, `items`)\n- callbacks: semantic names (`onSuccess`, `handleSubmit`)\n\n## Examples\n- `x` -> `itemCount`\n- `tmp` -> `temporaryBuffer`\n- `res` -> `apiResponse`\n- `d` -> `userData`\n- `arr` -> `filteredItems`\n\n## Safety Rules\n- do not rename public/exported symbols unless explicitly requested\n- do not rename object keys that are part of API pa",
    "source": "knowledge/javascript/rename_patterns.md"
  },
  {
    "id": "1c48a41a13cb7330",
    "text": "ilteredItems`\n\n## Safety Rules\n- do not rename public/exported symbols unless explicitly requested\n- do not rename object keys that are part of API payloads/contracts\n- preserve semantics and scope\n- keep naming consistent with project conventions\n\n## Expected Agent Output\n- identify unclear names and explain why\n- propose safer, meaningful renamings\n- avoid renaming public/external symbols unless requested\n- return full refactored code with naming consistency",
    "source": "knowledge/javascript/rename_patterns.md"
  },
  {
    "id": "6f4eddbf404561ab",
    "text": "# Python Complexity Refactoring Patterns\n\n## Goal\nReduce cyclomatic/cognitive complexity while preserving exact behavior.\n\n## Core Principles\n- Preserve semantics exactly (outputs, exceptions, side effects, order of execution)\n- Prefer small safe refactors over aggressive rewrites\n- Improve readability and maintainability\n- Keep public APIs unchanged unless explicitly requested\n\n## Common Complexity Smells\n- Deeply nested `if/elif/else`\n- Long functions mixing multiple responsibilities\n- Repeated conditional branches\n- Complex boolean expressions\n- Nested loops with multiple responsibilities\n- Implicit control flow (flags, break/continue scattered everywhere)\n- Duplicate control-flow patterns\n\n## Refactoring Patterns\n\n### 1. Guard Clauses / Early Return\n**Use when**\n- Function has nested validations or preconditions\n\n**Before**\n- `if ...: if ...: if ...: main logic`\n\n**After**\n- Return early for invalid conditions, keep main path flat\n\n**Benefits**\n- Reduces nesting\n- Improves readability\n\n**Safety Notes**\n- Keep same return values and exception behavior\n- Do not change evaluation order of side effects\n\n---\n\n### 2. Extract Helper Function\n**Use when**\n- A block of code performs a d",
    "source": "knowledge/python/complexity_patterns.md"
  },
  {
    "id": "bf63c73d6a7b91c2",
    "text": "d exception behavior\n- Do not change evaluation order of side effects\n\n---\n\n### 2. Extract Helper Function\n**Use when**\n- A block of code performs a distinct sub-task\n- Repeated logic appears in multiple places\n\n**Benefits**\n- Smaller functions\n- Better testability\n- Easier reasoning\n\n**Safety Notes**\n- Preserve parameters and data dependencies\n- Do not accidentally capture mutable shared state differently\n\n---\n\n### 3. Split Function by Responsibility\n**Use when**\n- One function validates, transforms, persists, logs, and formats result all at once\n\n**Approach**\n- Separate validation / transformation / persistence / formatting helpers\n\n**Safety Notes**\n- Preserve execution order (especially DB writes, logs, API calls)\n- Preserve raised exceptions and messages if relied upon\n\n---\n\n### 4. Simplify Boolean Logic\n**Use when**\n- Complex boolean expressions are hard to read\n- Repeated negations, chained conditions, nested booleans\n\n**Approach**\n- Extract named predicates:\n  - `is_valid_user(...)`\n  - `has_access(...)`\n\n**Safety Notes**\n- Preserve short-circuit semantics\n- Preserve laziness if condition includes function calls with side effects\n\n---\n\n### 5. Replace Repeated Branch Bodies w",
    "source": "knowledge/python/complexity_patterns.md"
  },
  {
    "id": "04721a8dcabd5ec4",
    "text": "serve short-circuit semantics\n- Preserve laziness if condition includes function calls with side effects\n\n---\n\n### 5. Replace Repeated Branch Bodies with Dispatch (Carefully)\n**Use when**\n- Many `if/elif` branches map simple keys to handlers or values\n\n**Approach**\n- Use dictionary mapping or handler functions\n\n**Safety Notes**\n- Only if branch order does not change behavior\n- Be careful with fallbacks/default behavior and exceptions\n\n---\n\n### 6. Flatten Nested Loops by Extracting Inner Logic\n**Use when**\n- Nested loops contain dense conditional logic\n\n**Approach**\n- Extract inner operation into helper\n- Use clear variable names\n- Optionally continue early for skipped cases\n\n**Safety Notes**\n- Preserve loop order and mutation timing\n- Preserve append/update side effects exactly\n\n---\n\n### 7. Introduce Intermediate Variables with Meaningful Names\n**Use when**\n- A single line contains many chained operations or conditions\n\n**Benefits**\n- Lower cognitive load\n- Easier debugging\n\n**Safety Notes**\n- Avoid changing evaluation timing when functions have side effects\n\n---\n\n### 8. Consolidate Duplicate Conditions\n**Use when**\n- Same condition repeated in multiple branches\n\n**Approach**\n- Com",
    "source": "knowledge/python/complexity_patterns.md"
  },
  {
    "id": "54fb23ab039c6f0e",
    "text": "ctions have side effects\n\n---\n\n### 8. Consolidate Duplicate Conditions\n**Use when**\n- Same condition repeated in multiple branches\n\n**Approach**\n- Compute once into a named predicate or normalize branching structure\n\n**Safety Notes**\n- Ensure condition is evaluated same number of times if side effects exist\n\n---\n\n## What NOT to Do (Unless Explicitly Safe)\n- Do not change public function signatures\n- Do not replace loops with comprehensions if side effects / ordering become unclear\n- Do not introduce caching/memoization (behavior/performance semantics may change)\n- Do not silently catch exceptions\n- Do not change logging behavior\n- Do not reorder validations if exceptions differ\n\n## ComplexityAgent Decision Heuristics\n1. Prefer guard clauses first\n2. Then extract helpers for repeated / dense blocks\n3. Then simplify boolean logic\n4. Avoid structural rewrites if uncertain\n5. If risk of semantic drift is high, return minimal refactor",
    "source": "knowledge/python/complexity_patterns.md"
  },
  {
    "id": "e2a8e14f1bf70b73",
    "text": "# Python Duplication Refactoring Patterns\n\n## Goal\nReduce duplicated code while preserving behavior exactly.\n\n## Types of Duplication\n- Exact duplicate blocks\n- Near-duplicate blocks (same structure, different literals/fields)\n- Repeated loops with same processing shape\n- Repeated validation/error handling\n- Repeated mapping/formatting logic\n\n## Refactoring Patterns\n\n### 1. Extract Helper Function\n**Use when**\n- Same block appears 2+ times\n\n**Benefits**\n- Single source of truth\n- Easier maintenance\n\n**Safety Notes**\n- Preserve parameter order and default behavior\n- Preserve exceptions and side effects\n\n---\n\n### 2. Parameterize Differences\n**Use when**\n- Blocks differ only by field names, labels, constants\n\n**Approach**\n- Extract helper with parameters\n- Pass field names / callbacks / formatters\n\n**Safety Notes**\n- Keep exact output format\n- Preserve branch-specific behavior if any hidden differences exist\n\n---\n\n### 3. Extract Validation Utility\n**Use when**\n- Same required-field checks repeated across functions\n\n**Safety Notes**\n- Preserve exact error keys/messages if relied upon by callers/tests\n\n---\n\n### 4. Extract Formatter / Serializer\n**Use when**\n- Same dict-building / respon",
    "source": "knowledge/python/duplication_patterns.md"
  },
  {
    "id": "5c8eeed2ea6fa353",
    "text": "serve exact error keys/messages if relied upon by callers/tests\n\n---\n\n### 4. Extract Formatter / Serializer\n**Use when**\n- Same dict-building / response formatting repeated\n\n**Safety Notes**\n- Preserve field names and order when important for downstream consumers\n\n---\n\n### 5. Consolidate Repeated Try/Except Structure\n**Use when**\n- Multiple functions repeat parse / convert / fallback logic\n\n**Safety Notes**\n- Preserve exception types caught and fallback return values\n\n---\n\n### 6. Loop Unification (Careful)\n**Use when**\n- Multiple loops iterate similarly over same data shape\n\n**Safety Notes**\n- Preserve mutation timing and append order\n- Do not merge loops if intermediate state matters\n\n## What NOT to Do\n- Do not over-abstract tiny duplicates if readability decreases\n- Do not combine code paths with subtle semantic differences\n- Do not introduce generic helpers that obscure domain intent\n\n## DuplicationAgent Heuristics\n1. Confirm semantic equivalence before deduplicating\n2. Prefer local helper extraction\n3. Keep helper names domain-meaningful\n4. If uncertain, deduplicate only exact matches",
    "source": "knowledge/python/duplication_patterns.md"
  },
  {
    "id": "ada8732314198334",
    "text": "ningful\n4. If uncertain, deduplicate only exact matches",
    "source": "knowledge/python/duplication_patterns.md"
  },
  {
    "id": "63adbf63e2bfff8b",
    "text": "# Python Import Refactoring Patterns\n\n## Goal\nImprove import hygiene while preserving runtime behavior.\n\n## Common Import Smells\n- Unused imports\n- Duplicate imports\n- Imports inside functions without reason (or with no comment)\n- Wildcard imports (`from x import *`)\n- Inconsistent grouping/order\n- Aliases with unclear names\n- Circular import workarounds used incorrectly\n\n## Refactoring Patterns\n\n### 1. Remove Unused Imports\n**Use when**\n- Imported names are never referenced\n\n**Safety Notes**\n- Watch for imports used for side effects\n- Watch for typing-only imports (`TYPE_CHECKING`)\n- Watch for framework/plugin registration imports\n\n---\n\n### 2. Merge Duplicate Imports\n**Use when**\n- Same module imported multiple times\n\n**Safety Notes**\n- Preserve aliasing if actually used differently\n\n---\n\n### 3. Replace Wildcard Imports with Explicit Imports\n**Use when**\n- Readability / maintainability issue\n\n**Safety Notes**\n- Risky if many symbols implicit; apply only when used names are clear\n\n---\n\n### 4. Group and Order Imports\nTypical order (PEP8 style):\n1. Standard library\n2. Third-party\n3. Local application imports\n\n**Safety Notes**\n- Reordering can affect behavior in rare side-effectful im",
    "source": "knowledge/python/import_patterns.md"
  },
  {
    "id": "93e968b4174297d1",
    "text": "8 style):\n1. Standard library\n2. Third-party\n3. Local application imports\n\n**Safety Notes**\n- Reordering can affect behavior in rare side-effectful imports\n- Be conservative if imports trigger initialization\n\n---\n\n### 5. Keep Intentional Local Imports\n**Use when**\n- Imports are inside function for lazy loading / optional dependency / circular import fix\n\n**Rule**\n- Do not move local imports unless clearly safe and requested\n\n## What NOT to Do\n- Do not remove imports used indirectly by decorators/metaclasses/plugins if uncertain\n- Do not reorder imports that may alter side effects\n- Do not force style-only changes if they risk behavior\n\n## ImportAgent Heuristics\n1. Prefer removing clearly unused imports\n2. Keep side-effect imports unless explicit evidence they are safe to remove\n3. Be conservative around optional imports and `try/except ImportError`",
    "source": "knowledge/python/import_patterns.md"
  },
  {
    "id": "685bf229d394c779",
    "text": "# Python Long Function Refactoring Patterns\n\n## Goal\nSplit overly long functions into smaller, understandable units while preserving behavior.\n\n## Long Function Smells\n- >20-40 lines with mixed responsibilities\n- Validation + transformation + persistence + formatting in one function\n- Many nested branches\n- Repeated temporary variables across unrelated steps\n- Hard-to-name variables due to overloaded logic\n\n## Refactoring Patterns\n\n### 1. Extract Validation Phase\n- Move input checks into `_validate_*` helper\n- Keep exact exception types/messages\n\n### 2. Extract Transformation Phase\n- Move parsing/normalization into `_normalize_*` helper\n- Preserve conversion rules and fallback behavior\n\n### 3. Extract Persistence / Side-Effect Phase\n- Move DB/file/network actions into `_save_*` / `_execute_*`\n- Preserve ordering relative to logs and mutations\n\n### 4. Extract Formatting / Response Phase\n- Return final dict/object via helper to reduce clutter\n\n### 5. Introduce Orchestrator Function Shape\nKeep public function as:\n1. validate\n2. transform\n3. execute\n4. format result\n\nThis makes code easier to follow while preserving the same API.\n\n## Safety Rules\n- Do not change function signature unle",
    "source": "knowledge/python/long_function_patterns.md"
  },
  {
    "id": "5942c6e562c10cd0",
    "text": "\n3. execute\n4. format result\n\nThis makes code easier to follow while preserving the same API.\n\n## Safety Rules\n- Do not change function signature unless requested\n- Preserve order of side effects (DB, logging, notifications)\n- Preserve mutation timing\n- Preserve exceptions and return shape\n- Avoid splitting tiny functions excessively (over-fragmentation)\n\n## LongFunctionAgent Heuristics\n1. Extract only coherent blocks\n2. Keep helper names descriptive\n3. Prefer private helpers (`_name`) for internal refactors\n4. Minimal safe split if uncertainty exists",
    "source": "knowledge/python/long_function_patterns.md"
  },
  {
    "id": "c25c76d527745366",
    "text": "# Python Rename Refactoring Patterns\n\n## Goal\nImprove readability by renaming unclear identifiers while preserving behavior and compatibility.\n\n## Naming Rules (Python)\n- Use `snake_case` for variables and functions\n- Use `PascalCase` for classes\n- Use descriptive names over short ambiguous names\n- Boolean variables should read like predicates:\n  - `is_valid`, `has_items`, `can_publish`, `should_retry`\n\n## Common Rename Smells\n- Single-letter names outside tiny loops (`x`, `d`, `n`, `k`)\n- Ambiguous names (`data`, `obj`, `tmp`, `res`)\n- Misleading names (`users` for a single user)\n- Non-domain names where domain concept is clear\n- Inconsistent naming in same scope\n\n## Safe Rename Strategy\n1. Rename local variables first\n2. Rename private helpers next\n3. Rename loop variables only if unclear\n4. Avoid renaming public API names unless explicitly allowed\n5. Avoid renaming framework-required names\n6. Avoid renaming imported symbols if it may break module contracts\n\n## Good Rename Examples\n- `x` -> `items`\n- `n` -> `item_count`\n- `res` -> `response`\n- `d` -> `payload` / `data` (if domain unknown)\n- `ok` -> `is_success` / `is_allowed`\n\n## What NOT to Do\n- Do not rename public methods used",
    "source": "knowledge/python/rename_patterns.md"
  },
  {
    "id": "9b6862459b978f18",
    "text": "response`\n- `d` -> `payload` / `data` (if domain unknown)\n- `ok` -> `is_success` / `is_allowed`\n\n## What NOT to Do\n- Do not rename public methods used externally without permission\n- Do not rename magic names (`__init__`, framework hooks)\n- Do not rename variables if the new name is speculative and may be wrong\n- Do not rename if it hurts readability more than it helps\n\n## RenameAgent Heuristics\n- Prefer high-confidence renames only\n- Preserve semantics and references\n- Keep changes minimal and clear\n",
    "source": "knowledge/python/rename_patterns.md"
  },
  {
    "id": "9b807ec40e38c1fd",
    "text": "# Project Conventions (PFE Agentic Refactoring) - Shared\n\n## Objectif\nDécrire les conventions de ce projet multi-agents de refactoring afin que les agents produisent des résultats compatibles avec l’architecture existante.\n\n---\n\n## 1. Architecture globale\nLe projet est organisé autour de :\n- plusieurs agents de refactoring spécialisés (Rename, Complexity, Duplication, Import, LongFunction)\n- un orchestrateur (linéaire ou LangGraph)\n- des agents de post-traitement/validation (PatchAgent, TestAgent)\n- une configuration de température par agent (`TemperatureConfig`)\n\nLes agents retournent un format standardisé de résultat.\n\n---\n\n## 2. Contrat de sortie standard des agents\nUn agent doit retourner un dictionnaire avec au minimum :\n- `name`\n- `analysis`\n- `proposal`\n\nOptionnel :\n- `temperature_used`\n- autres métadonnées spécifiques (`warnings`, `metrics`, etc.)\n\n### Exemple minimal\n```python\n{\n    \"name\": \"ComplexityAgent\",\n    \"analysis\": [...],\n    \"proposal\": \"...refactored code...\"\n}",
    "source": "knowledge/shared/project_conventions.md"
  },
  {
    "id": "fb764b64e1304cef",
    "text": "# Refactoring General Patterns (Shared)\n\n## Objectif\nFournir des patterns généraux de refactoring utilisables par plusieurs agents.\n\n---\n\n## 1. Small Safe Steps\n- Préférer plusieurs petites modifications sûres à une grosse transformation risquée.\n- Après chaque étape : vérifier la cohérence du code.\n\n### Exemple\n- Rename variable\n- Extract helper function\n- Simplify conditional\n- Re-run tests\n\n---\n\n## 2. Extract Function / Method\n### Quand utiliser\n- Bloc de code long\n- Responsabilité mélangée\n- Logique répétée\n- Noms de variables difficiles à comprendre\n\n### Bonnes pratiques\n- Choisir un nom explicite\n- Passer uniquement les paramètres nécessaires\n- Retourner uniquement les résultats nécessaires\n- Préserver l’ordre des effets de bord\n\n---\n\n## 3. Guard Clauses\n### But\nRéduire l’imbrication inutile (nested if/else) pour améliorer lisibilité/complexité cognitive.\n\n### Bonnes pratiques\n- Vérifier les cas d’erreur / early exit au début\n- Garder le “happy path” visible\n- Ne pas modifier la logique de retour\n\n---\n\n## 4. Replace Magic Numbers / Strings\n### But\nAméliorer la lisibilité via des constantes nommées.\n\n### Attention\n- Ne pas extraire si la valeur est purement locale et évidente\n",
    "source": "knowledge/shared/refactoring_general_patterns.md"
  },
  {
    "id": "f6e6fe7c3e4c5954",
    "text": "s / Strings\n### But\nAméliorer la lisibilité via des constantes nommées.\n\n### Attention\n- Ne pas extraire si la valeur est purement locale et évidente\n- Conserver le bon scope (local/module/class)\n\n---\n\n## 5. Consolidate Duplicate Logic\n### But\nFactoriser du code dupliqué dans une fonction/helper commun(e).\n\n### Attention\n- Ne pas sur-abstraire\n- Vérifier que les blocs sont réellement équivalents\n- Préserver les différences de comportement subtiles\n\n---\n\n## 6. Simplify Conditionals (Safe)\n### Exemples\n- Fusionner conditions identiques\n- Supprimer `else` après `return` (si sûr)\n- Extraire sous-condition complexe dans variable booléenne nommée\n\n### Attention\n- Respecter short-circuit\n- Respecter ordre d’évaluation\n- Ne pas déplacer des appels avec effets de bord\n\n---\n\n## 7. Improve Naming (Local & Safe)\n### Cible\n- Variables locales\n- paramètres internes\n- helpers privés\n\n### Bonnes pratiques\n- Noms explicites selon rôle métier/technique\n- Booléens commencent par `is_`, `has_`, `can_`, `should_` (langage/style dépendant)\n- Éviter noms trop courts (`x`, `tmp`, `data`) sauf cas local trivial\n\n### Attention\n- Ne pas renommer API publique sans plan\n- Ne pas casser reflection/serialization",
    "source": "knowledge/shared/refactoring_general_patterns.md"
  },
  {
    "id": "b44e07c3adc5e620",
    "text": "op courts (`x`, `tmp`, `data`) sauf cas local trivial\n\n### Attention\n- Ne pas renommer API publique sans plan\n- Ne pas casser reflection/serialization/framework bindings\n\n---\n\n## 8. Imports Cleanup\n### But\n- Supprimer imports inutilisés\n- Dédupliquer\n- Organiser l’ordre des imports (si convention)\n\n### Attention\n- Effets de bord d’import\n- Imports dynamiques\n- Imports seulement utilisés dans type hints / runtime conditionnel\n\n---\n\n## 9. Long Function Decomposition\n### Techniques\n- Extract helpers par responsabilité\n- Isoler validation\n- Isoler transformation de données\n- Isoler I/O\n\n### Attention\n- Préserver variables mutées / closures / state partagé\n- Préserver ordre exact des étapes\n\n---\n\n## 10. Refactoring Output Rules (pour LLM agents)\nQuand un agent propose une modification :\n1. Mentionner brièvement les problèmes détectés\n2. Fournir le code refactoré complet (ou patch clair)\n3. Expliquer pourquoi la sémantique est préservée\n4. Mentionner les limites / risques éventuels\n\n---\n\n## Anti-patterns à éviter\n- “Big rewrite” sans nécessité\n- Changement de style + logique en même temps\n- Optimisations prématurées\n- Abstractions inutiles\n- Renommages massifs non maîtrisés",
    "source": "knowledge/shared/refactoring_general_patterns.md"
  },
  {
    "id": "22702ecfd835aa2b",
    "text": "ité\n- Changement de style + logique en même temps\n- Optimisations prématurées\n- Abstractions inutiles\n- Renommages massifs non maîtrisés",
    "source": "knowledge/shared/refactoring_general_patterns.md"
  },
  {
    "id": "31ff813adbae1fb1",
    "text": "# Semantic Preservation Rules (Shared)\n\n## Objectif\nToutes les transformations de refactoring doivent préserver le comportement fonctionnel du code.\n\n## Règles obligatoires (tous agents)\n\n### 1. Préservation du comportement\n- Ne pas changer les valeurs de retour.\n- Ne pas changer les effets de bord.\n- Ne pas changer les exceptions levées (type/message/moment si possible).\n- Ne pas changer l’ordre d’exécution des opérations sensibles.\n\n### 2. Préservation des APIs\n- Ne pas modifier les signatures publiques (noms de fonctions, paramètres, ordre des paramètres) sauf demande explicite.\n- Ne pas renommer les classes/fonctions exportées publiquement sans stratégie de migration.\n- Ne pas casser les points d’entrée existants.\n\n### 3. Préservation de la logique conditionnelle\n- Conserver la logique booléenne exacte.\n- Respecter le short-circuit (`and`, `or`).\n- Éviter les simplifications risquées qui changent les cas limites.\n\n### 4. Préservation des mutations / état\n- Ne pas modifier le timing des mutations (append, update, assignment, DB writes, file writes).\n- Ne pas déplacer des effets de bord hors de leur contexte sans preuve de sécurité.\n- Respecter les états globaux / partagés / cach",
    "source": "knowledge/shared/semantic_preservation_rules.md"
  },
  {
    "id": "eb2c066cdff453a7",
    "text": "tes, file writes).\n- Ne pas déplacer des effets de bord hors de leur contexte sans preuve de sécurité.\n- Respecter les états globaux / partagés / caches.\n\n### 5. Préservation I/O et environnement\n- Conserver les appels I/O (fichiers, réseau, logs) et leur ordre.\n- Ne pas supprimer des logs fonctionnels sans validation.\n- Ne pas modifier la gestion du temps, hasard, seeds, timestamps.\n\n### 6. Imports et dépendances\n- Ne pas supprimer un import si son import déclenche un effet de bord au chargement.\n- Conserver les imports nécessaires à la compatibilité runtime/type checking.\n\n### 7. Exceptions et erreurs\n- Conserver les `try/except/finally` et leur sémantique.\n- Ne pas transformer silencieusement une exception en comportement différent.\n- Préserver les messages critiques si utilisés par tests/monitoring.\n\n## Règle de sécurité\nSi un refactor peut améliorer la lisibilité mais risque de changer la sémantique :\n- **ne pas l’appliquer**\n- ou proposer le changement avec mention explicite du risque.\n\n## Stratégie de validation recommandée\nAvant d’accepter un refactor :\n1. Vérification syntaxique\n2. Tests unitaires / statiques\n3. Comparaison comportementale sur cas critiques\n4. Review des e",
    "source": "knowledge/shared/semantic_preservation_rules.md"
  },
  {
    "id": "0ea95615dd8f37ed",
    "text": "nt d’accepter un refactor :\n1. Vérification syntaxique\n2. Tests unitaires / statiques\n3. Comparaison comportementale sur cas critiques\n4. Review des effets de bord\n\n## Priorité\nLa préservation sémantique est prioritaire sur :\n- style\n- concision\n- “élégance”\n- optimisation micro-performance",
    "source": "knowledge/shared/semantic_preservation_rules.md"
  },
  {
    "id": "00e4b12b04f5a5e6",
    "text": "# core/experiment_report.py\n\nclass TemperatureExperimentReport:\n    \"\"\"\n    Génère des rapports sur l'impact de la température.\n    \"\"\"\n    \n    @staticmethod\n    def generate_report(experiment_results):\n        \"\"\"Génère un rapport détaillé\"\"\"\n        \n        report = {\n            \"summary\": {\n                \"total_experiments\": len(experiment_results),\n                \"agents_tested\": list(set(\n                    agent[\"name\"] \n                    for exp in experiment_results \n                    for agent in exp.get(\"results\", [])\n                ))\n            },\n            \"findings\": [],\n            \"recommendations\": []\n        }\n        \n        # Analyser l'impact sur chaque agent\n        agent_performance = {}\n        \n        for exp in experiment_results:\n            temp = exp[\"temperature\"]\n            \n            for agent_result in exp.get(\"results\", []):\n                agent_name = agent_result[\"name\"]\n                \n                if agent_name not in agent_performance:\n                    agent_performance[agent_name] = []\n                \n                # Mesures de qualité (simples)\n                proposal = agent_result[\"proposal\"]\n               ",
    "source": "core/experiment_report.py"
  },
  {
    "id": "026f74d9bc659b5e",
    "text": "e[agent_name] = []\n                \n                # Mesures de qualité (simples)\n                proposal = agent_result[\"proposal\"]\n                quality_metrics = {\n                    \"temperature\": temp,\n                    \"length\": len(proposal),\n                    \"lines\": len(proposal.split('\\n')),\n                    \"unique_tokens\": len(set(proposal.split())),\n                    \"readability_score\": calculate_readability(proposal)  # À implémenter\n                }\n                \n                agent_performance[agent_name].append(quality_metrics)\n        \n        # Générer des recommandations basées sur les données\n        for agent, metrics_list in agent_performance.items():\n            # Trouver la température optimale (longueur la plus cohérente)\n            optimal_temp = TemperatureExperimentReport._find_optimal_temperature(metrics_list)\n            \n            report[\"findings\"].append({\n                \"agent\": agent,\n                \"optimal_temperature\": optimal_temp,\n                \"performance_by_temperature\": metrics_list\n            })\n        \n        return report\n    \n    @staticmethod\n    def _find_optimal_temperature(metrics_list):\n        \"\"",
    "source": "core/experiment_report.py"
  },
  {
    "id": "cea51859ebcf8fe7",
    "text": "rature\": metrics_list\n            })\n        \n        return report\n    \n    @staticmethod\n    def _find_optimal_temperature(metrics_list):\n        \"\"\"Trouve la température optimale basée sur les métriques\"\"\"\n        # Simplifié : choisit la température avec la longueur la plus cohérente\n        if not metrics_list:\n            return 0.3\n        \n        # Calculer l'écart-type des longueurs pour chaque température\n        temp_to_lengths = {}\n        for metrics in metrics_list:\n            temp = metrics[\"temperature\"]\n            if temp not in temp_to_lengths:\n                temp_to_lengths[temp] = []\n            temp_to_lengths[temp].append(metrics[\"length\"])\n        \n        # Trouver la température avec le plus petit écart-type\n        optimal_temp = 0.3\n        min_std = float('inf')\n        \n        for temp, lengths in temp_to_lengths.items():\n            if len(lengths) > 1:\n                import statistics\n                std = statistics.stdev(lengths)\n                if std < min_std:\n                    min_std = std\n                    optimal_temp = temp\n        \n        return optimal_temp",
    "source": "core/experiment_report.py"
  },
  {
    "id": "ed7138b260b94b09",
    "text": "\n                    optimal_temp = temp\n        \n        return optimal_temp",
    "source": "core/experiment_report.py"
  },
  {
    "id": "272e9bff374339d7",
    "text": "from __future__ import annotations\nfrom pathlib import Path\nfrom typing import List, Set\nimport ast\nimport re\nimport hashlib\n\nfrom .graphrag_store import GraphRAGStore, Chunk\n\n\ndef chunk_text(text: str, max_chars: int = 1200, overlap: int = 150) -> List[str]:\n    chunks = []\n    i = 0\n    while i < len(text):\n        chunks.append(text[i:i + max_chars])\n        i += max_chars - overlap\n    return chunks\n\n\ndef stable_id(s: str) -> str:\n    return hashlib.sha1(s.encode(\"utf-8\", errors=\"ignore\")).hexdigest()[:16]\n\n\ndef extract_symbols_python(code: str) -> Set[str]:\n    \"\"\"Classes, fonctions, imports via AST.\"\"\"\n    symbols: Set[str] = set()\n    try:\n        tree = ast.parse(code)\n    except Exception:\n        return symbols\n\n    for node in ast.walk(tree):\n        if isinstance(node, ast.ClassDef):\n            symbols.add(node.name)\n        elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n            symbols.add(node.name)\n        elif isinstance(node, ast.Import):\n            for alias in node.names:\n                symbols.add(alias.name.split(\".\")[0])\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                symbols.add(node.module.sp",
    "source": "core/graphrag_ingest.py"
  },
  {
    "id": "fa73b52f1f6b1bdf",
    "text": "ls.add(alias.name.split(\".\")[0])\n        elif isinstance(node, ast.ImportFrom):\n            if node.module:\n                symbols.add(node.module.split(\".\")[0])\n            for alias in node.names:\n                symbols.add(alias.name)\n    return symbols\n\n\ndef extract_mentions_symbols(text: str) -> Set[str]:\n    \"\"\"Heuristique: CamelCase + identifiants snake_case.\"\"\"\n    camel = set(re.findall(r\"\\b[A-Z][a-zA-Z0-9_]{2,}\\b\", text))\n    snake = set(re.findall(r\"\\b[a-z_][a-z0-9_]{2,}\\b\", text))\n    bad = {\"return\", \"import\", \"from\", \"class\", \"def\", \"self\", \"True\", \"False\", \"None\"}\n    return {t for t in (camel | snake) if t not in bad and 2 < len(t) <= 60}\n\n\ndef ingest(paths: List[str], patterns=(\"**/*.py\", \"**/*.md\", \"**/*.txt\")):\n    store = GraphRAGStore()\n    all_chunks: List[Chunk] = []\n\n    for base in paths:\n        base_path = Path(base)\n        if not base_path.exists():\n            continue\n\n        for pat in patterns:\n            for file in base_path.glob(pat):\n                try:\n                    text = file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n                except Exception:\n                    continue\n\n                file_node = f\"file:{file.as_posix",
    "source": "core/graphrag_ingest.py"
  },
  {
    "id": "05380776040560d9",
    "text": "t(encoding=\"utf-8\", errors=\"ignore\")\n                except Exception:\n                    continue\n\n                file_node = f\"file:{file.as_posix()}\"\n                store.g.add_node(file_node, type=\"file\", path=file.as_posix())\n\n                # Symbols defined/imported in this file\n                symbols = set()\n                if file.suffix == \".py\":\n                    symbols |= extract_symbols_python(text)\n\n                for sym in symbols:\n                    sym_node = f\"symbol:{sym}\"\n                    store.g.add_node(sym_node, type=\"symbol\", name=sym)\n                    store.g.add_edge(sym_node, file_node, rel=\"defined_in\")\n\n                # Chunk nodes + mention edges\n                for part in chunk_text(text):\n                    cid = stable_id(file.as_posix() + \":\" + part[:250])\n                    chunk_node = f\"chunk:{cid}\"\n                    all_chunks.append(Chunk(id=cid, text=part, source=file.as_posix()))\n\n                    store.g.add_node(chunk_node, type=\"chunk\", id=cid, source=file.as_posix())\n                    store.g.add_edge(chunk_node, file_node, rel=\"in_file\")\n\n                    # Mentions -> symbols\n                    mentions ",
    "source": "core/graphrag_ingest.py"
  },
  {
    "id": "bb2639ac5ed06c18",
    "text": "))\n                    store.g.add_edge(chunk_node, file_node, rel=\"in_file\")\n\n                    # Mentions -> symbols\n                    mentions = extract_mentions_symbols(part)\n                    for m in mentions:\n                        m_node = f\"symbol:{m}\"\n                        store.g.add_node(m_node, type=\"symbol\", name=m)\n                        store.g.add_edge(chunk_node, m_node, rel=\"mentions\")\n\n    store.build_vectors(all_chunks)\n    store.save()\n    print(f\"✅ GraphRAG indexed {len(all_chunks)} chunks. Saved to graphrag/\")\n\nif __name__ == \"__main__\":\n    ingest([\"knowledge\", \"core\", \"agents\"])\n",
    "source": "core/graphrag_ingest.py"
  },
  {
    "id": "7c84beaf2800be91",
    "text": "from __future__ import annotations\nfrom typing import List, Dict, Any, Set\nimport networkx as nx\n\nfrom .graphrag_store import GraphRAGStore\n\n\nclass GraphRAGRetriever:\n    def __init__(self):\n        self.store = GraphRAGStore()\n\n    def _extract_symbols_from_text(self, text: str) -> Set[str]:\n        # utilise les nodes existants du graphe: on prend les symboles connus qui apparaissent dans la query\n        # MVP: match simple par inclusion (ok sur repo)\n        symbols = set()\n        for n, data in self.store.g.nodes(data=True):\n            if data.get(\"type\") == \"symbol\":\n                name = data.get(\"name\")\n                if name and name in text:\n                    symbols.add(name)\n        return symbols\n\n    def _neighbors_hops(self, start_nodes: List[str], hops: int = 2) -> Set[str]:\n        visited = set(start_nodes)\n        frontier = set(start_nodes)\n        for _ in range(hops):\n            nxt = set()\n            for node in frontier:\n                nxt |= set(self.store.g.neighbors(node))\n            nxt -= visited\n            visited |= nxt\n            frontier = nxt\n        return visited\n\n    def retrieve(self, query: str, k_seeds: int = 4, hops: int = 2, max",
    "source": "core/graphrag_retriever.py"
  },
  {
    "id": "e7e5b94b65bd91e9",
    "text": "\n            visited |= nxt\n            frontier = nxt\n        return visited\n\n    def retrieve(self, query: str, k_seeds: int = 4, hops: int = 2, max_chunks: int = 8) -> Dict[str, Any]:\n        # 1) vector seeds\n        seeds = self.store.vector_search(query, k=k_seeds)\n\n        seed_chunk_ids = [m[\"id\"] for (m, _) in seeds]\n        seed_chunk_nodes = [f\"chunk:{cid}\" for cid in seed_chunk_ids if f\"chunk:{cid}\" in self.store.g]\n\n        # 2) symbols from query + seeds\n        seed_text = \"\\n\".join([m[\"text\"] for (m, _) in seeds])\n        symbols = self._extract_symbols_from_text(query + \"\\n\" + seed_text)\n\n        symbol_nodes = [f\"symbol:{s}\" for s in symbols if f\"symbol:{s}\" in self.store.g]\n\n        # 3) expand graph\n        start = seed_chunk_nodes + symbol_nodes\n        expanded_nodes = self._neighbors_hops(start, hops=hops)\n\n        # 4) collect chunks from expanded neighborhood\n        chunk_nodes = [n for n in expanded_nodes if n.startswith(\"chunk:\")]\n        # prioritize: seeds first\n        ordered_chunk_nodes = seed_chunk_nodes + [c for c in chunk_nodes if c not in seed_chunk_nodes]\n        ordered_chunk_nodes = ordered_chunk_nodes[:max_chunks]\n\n        # build context pa",
    "source": "core/graphrag_retriever.py"
  },
  {
    "id": "016c7760020d660d",
    "text": "des + [c for c in chunk_nodes if c not in seed_chunk_nodes]\n        ordered_chunk_nodes = ordered_chunk_nodes[:max_chunks]\n\n        # build context pack\n        chunks_out = []\n        for cn in ordered_chunk_nodes:\n            cid = cn.split(\"chunk:\")[1]\n            meta_item = next((x for x in self.store.meta if x[\"id\"] == cid), None)\n            if meta_item:\n                chunks_out.append(meta_item)\n\n        # graph facts (light)\n        facts = []\n        for s in list(symbols)[:12]:\n            sn = f\"symbol:{s}\"\n            if sn in self.store.g:\n                neigh = list(self.store.g.neighbors(sn))[:8]\n                facts.append({\"symbol\": s, \"neighbors\": neigh})\n\n        return {\n            \"seeds\": [{\"source\": m[\"source\"], \"score\": sc} for (m, sc) in seeds],\n            \"symbols\": sorted(list(symbols))[:50],\n            \"chunks\": chunks_out,\n            \"facts\": facts,\n        }\n\n    @staticmethod\n    def format_context(pack: Dict[str, Any]) -> str:\n        parts = []\n        parts.append(\"### GraphRAG Context\")\n        if pack.get(\"symbols\"):\n            parts.append(\"**Symbols:** \" + \", \".join(pack[\"symbols\"][:20]))\n        parts.append(\"\\n### Retrieved Chunks\"",
    "source": "core/graphrag_retriever.py"
  },
  {
    "id": "b88f466ba39b3a9d",
    "text": "     if pack.get(\"symbols\"):\n            parts.append(\"**Symbols:** \" + \", \".join(pack[\"symbols\"][:20]))\n        parts.append(\"\\n### Retrieved Chunks\")\n        for c in pack.get(\"chunks\", []):\n            parts.append(f\"\\n[SOURCE: {c['source']}]\\n{c['text']}\")\n        return \"\\n\".join(parts)\n",
    "source": "core/graphrag_retriever.py"
  },
  {
    "id": "97b5f15f80e073a5",
    "text": "from __future__ import annotations\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import List, Tuple\nimport json\nimport pickle\n\nimport faiss\nimport networkx as nx\nfrom sentence_transformers import SentenceTransformer\n\n\n@dataclass\nclass Chunk:\n    id: str\n    text: str\n    source: str  # filepath\n\n\nclass GraphRAGStore:\n    def __init__(\n        self,\n        index_path: str = \"graphrag/faiss.index\",\n        meta_path: str = \"graphrag/meta.json\",\n        graph_path: str = \"graphrag/graph.gpickle\",\n    ):\n        self.index_path = Path(index_path)\n        self.meta_path = Path(meta_path)\n        self.graph_path = Path(graph_path)\n        self.index_path.parent.mkdir(parents=True, exist_ok=True)\n\n        self.model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n        self.index = None\n        self.meta: List[dict] = []\n        self.g = nx.Graph()\n\n        if self.index_path.exists() and self.meta_path.exists():\n            self.index = faiss.read_index(str(self.index_path))\n            self.meta = json.loads(self.meta_path.read_text(encoding=\"utf-8\"))\n\n        if self.graph_path.exists():\n            try:\n                with open(self.graph_path, \"rb\") as f:\n     ",
    "source": "core/graphrag_store.py"
  },
  {
    "id": "da963137dc2a2452",
    "text": "_path.read_text(encoding=\"utf-8\"))\n\n        if self.graph_path.exists():\n            try:\n                with open(self.graph_path, \"rb\") as f:\n                    self.g = pickle.load(f)\n            except Exception:\n                # Fallback: recréer un graphe vide si fichier corrompu/incompatible\n                self.g = nx.Graph()\n\n    def _embed(self, texts: List[str]):\n        emb = self.model.encode(texts, normalize_embeddings=True)\n        return emb.astype(\"float32\")\n\n    def save(self):\n        if self.index is not None:\n            faiss.write_index(self.index, str(self.index_path))\n\n        self.meta_path.write_text(\n            json.dumps(self.meta, ensure_ascii=False, indent=2),\n            encoding=\"utf-8\"\n        )\n\n        with open(self.graph_path, \"wb\") as f:\n            pickle.dump(self.g, f, protocol=pickle.HIGHEST_PROTOCOL)\n\n    def build_vectors(self, chunks: List[Chunk]):\n        if not chunks:\n            self.index = None\n            self.meta = []\n            return\n\n        vecs = self._embed([c.text for c in chunks])\n        dim = vecs.shape[1]\n        self.index = faiss.IndexFlatIP(dim)  # cosine similarity (normalize + inner product)\n        self.in",
    "source": "core/graphrag_store.py"
  },
  {
    "id": "7cb9e3efaddffb49",
    "text": "c in chunks])\n        dim = vecs.shape[1]\n        self.index = faiss.IndexFlatIP(dim)  # cosine similarity (normalize + inner product)\n        self.index.add(vecs)\n\n        self.meta = [{\"id\": c.id, \"text\": c.text, \"source\": c.source} for c in chunks]\n\n    def vector_search(self, query: str, k: int = 5) -> List[Tuple[dict, float]]:\n        if self.index is None:\n            return []\n\n        qv = self._embed([query])\n        scores, ids = self.index.search(qv, k)\n\n        out: List[Tuple[dict, float]] = []\n        for score, idx in zip(scores[0], ids[0]):\n            if idx == -1:\n                continue\n            out.append((self.meta[idx], float(score)))\n        return out",
    "source": "core/graphrag_store.py"
  },
  {
    "id": "b98d5ac496a3c099",
    "text": "\"\"\"\nNouvel orchestrateur basé sur LangGraph.\nRemplace core/orchestrator.py\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional\nimport time\nfrom langgraph.graph import StateGraph\n\n# Import de vos agents existants\nfrom agents.rename_agent import RenameAgent\nfrom agents.complexity_agent import ComplexityAgent\nfrom agents.duplication_agent import DuplicationAgent\nfrom agents.import_agent import ImportAgent\nfrom agents.long_function_agent import LongFunctionAgent\nfrom agents.merge_agent import MergeAgent\nfrom agents.test_agent import TestAgent\nfrom agents.patch_agent import PatchAgent\nfrom core.temperature_config import TemperatureConfig\n\n# Import des nouveaux modules LangGraph\nfrom .workflow_state import RefactorState\nfrom .workflow_graph import compile_graph\n\nclass LangGraphOrchestrator:\n    \"\"\"\n    Orchestrateur intelligent basé sur LangGraph.\n    Remplace l'orchestrateur linéaire par un workflow avec état.\n    \"\"\"\n    \n    def __init__(self, llm):\n        # Instanciation de tous les agents (comme avant)\n        self.agent_instances = {\n            \"RenameAgent\": RenameAgent(llm),\n            \"ComplexityAgent\": ComplexityAgent(llm),\n            \"DuplicationAgent\": DuplicationAgent(llm)",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "a2efbbf83c7caf76",
    "text": "           \"RenameAgent\": RenameAgent(llm),\n            \"ComplexityAgent\": ComplexityAgent(llm),\n            \"DuplicationAgent\": DuplicationAgent(llm),\n            \"ImportAgent\": ImportAgent(llm),\n            \"LongFunctionAgent\": LongFunctionAgent(llm),\n            \"TestAgent\": TestAgent(llm),\n            \"PatchAgent\": PatchAgent(llm),\n        }\n        self.merge_agent = MergeAgent(llm)\n        self.temperature_config = TemperatureConfig()\n        \n        # Compiler le graphe LangGraph\n        self.graph = compile_graph(self)\n    \n    def run_workflow(\n        self, \n        code: str, \n        language: str, \n        selected_agents: Optional[List[str]] = None,\n        auto_patch: bool = True,\n        auto_test: bool = True,\n        temperature_override: Optional[float] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Exécute le workflow complet de refactoring avec LangGraph.\n        \n        Args:\n            code: Code source à refactorer\n            language: Langage de programmation\n            selected_agents: Liste des agents à exécuter (tous si None)\n            auto_patch: Appliquer PatchAgent automatiquement\n            auto_test: Exécuter TestAgent automatiquement\n ",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "9dd1506fb062243c",
    "text": "nts à exécuter (tous si None)\n            auto_patch: Appliquer PatchAgent automatiquement\n            auto_test: Exécuter TestAgent automatiquement\n            temperature_override: Température globale (optionnel)\n            \n        Returns:\n            Dict avec tous les résultats\n        \"\"\"\n        # Déterminer les agents à exécuter\n        if selected_agents is None:\n            selected_agents = self.get_refactoring_agents()\n        \n        # Préparer l'état initial\n        initial_state: RefactorState = {\n            \"original_code\": code,\n            \"language\": language,\n            \"current_code\": code,\n            \"current_agent\": None,\n            \"agent_results\": [],\n            \"issues_detected\": [],\n            \"history\": [],\n            \"selected_agents\": selected_agents,\n            \"temperature_config\": self.temperature_config,\n            \"auto_patch\": auto_patch,\n            \"auto_test\": auto_test,\n            \"metrics\": {},\n            \"error\": None,\n            \"status\": \"initialized\",\n            \"patch_result\": None,\n            \"test_result\": None,\n            \"final_code\": None\n        }\n        \n        print(f\"🚀 Démarrage du workflow LangGraph avec {l",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "acf0f7c0518813ee",
    "text": "t\": None,\n            \"test_result\": None,\n            \"final_code\": None\n        }\n        \n        print(f\"🚀 Démarrage du workflow LangGraph avec {len(selected_agents)} agents\")\n        \n        # Exécuter le graphe\n        try:\n            final_state = self.graph.invoke(initial_state)\n            \n            # Exécuter PatchAgent et TestAgent (hors graphe pour compatibilité)\n            final_code = final_state.get(\"current_code\", code)\n            \n            if auto_patch:\n                print(\"🩹 Application du PatchAgent (post-graphe)...\")\n                patch_agent = self.agent_instances.get(\"PatchAgent\")\n                if patch_agent:\n                    patch_result = patch_agent.apply(final_code, language)\n                    final_state[\"patch_result\"] = patch_result\n                    final_code = patch_result.get(\"proposal\", final_code)\n            \n            if auto_test:\n                print(\"🧪 Exécution du TestAgent (post-graphe)...\")\n                test_agent = self.agent_instances.get(\"TestAgent\")\n                if test_agent:\n                    test_result = test_agent.apply(final_code, language)\n                    final_state[\"test_result\"] = test_",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "6d73278ee2cd2f1a",
    "text": "        if test_agent:\n                    test_result = test_agent.apply(final_code, language)\n                    final_state[\"test_result\"] = test_result\n            \n            final_state[\"final_code\"] = final_code\n            \n            return self._prepare_final_report(final_state)\n            \n        except Exception as e:\n            print(f\"❌ Erreur dans le workflow : {e}\")\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"refactored_code\": code,\n                \"final_code\": code\n            }\n    \n    def _prepare_final_report(self, final_state: RefactorState) -> Dict[str, Any]:\n        \"\"\"Prépare le rapport final à partir de l'état\"\"\"\n        return {\n            \"success\": True,\n            \"refactored_code\": final_state.get(\"final_code\", final_state[\"original_code\"]),\n            \"original_code\": final_state[\"original_code\"],\n            \"language\": final_state[\"language\"],\n            \"agent_results\": [\n                {\n                    \"name\": r.name,\n                    \"analysis\": r.analysis,\n                    \"temperature_used\": r.temperature_used\n                }\n                for r in final_st",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "7f81dfff8b5d0eb8",
    "text": "                \"analysis\": r.analysis,\n                    \"temperature_used\": r.temperature_used\n                }\n                for r in final_state.get(\"agent_results\", [])\n            ],\n            \"issues_detected\": final_state.get(\"issues_detected\", []),\n            \"history\": final_state.get(\"history\", []),\n            \"metrics\": final_state.get(\"metrics\", {}),\n            \"patch_result\": final_state.get(\"patch_result\"),\n            \"test_result\": final_state.get(\"test_result\"),\n            \"execution_time\": final_state.get(\"metrics\", {}).get(\"execution_time\", 0)\n        }\n    \n    # Méthodes compatibles avec l'ancienne API\n    def run_parallel(self, code, selected_agent_names, language, temperature_override=None):\n        \"\"\"\n        Compatibilité avec l'ancienne API.\n        Exécute les agents en \"parallèle\" (séquentiellement dans le graphe).\n        \"\"\"\n        result = self.run_workflow(\n            code=code,\n            language=language,\n            selected_agents=selected_agent_names,\n            auto_patch=False,  # PatchAgent séparé\n            auto_test=False,   # TestAgent séparé\n            temperature_override=temperature_override\n        )\n        \n      ",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "59cc8cccfed7355d",
    "text": " # PatchAgent séparé\n            auto_test=False,   # TestAgent séparé\n            temperature_override=temperature_override\n        )\n        \n        # Format compatible avec l'ancien retour\n        agent_results = []\n        for agent_result in result.get(\"agent_results\", []):\n            agent_results.append({\n                \"name\": agent_result[\"name\"],\n                \"analysis\": agent_result[\"analysis\"],\n                \"proposal\": result[\"refactored_code\"],  # Tous fusionnés\n                \"temperature_used\": agent_result.get(\"temperature_used\")\n            })\n        \n        return agent_results\n    \n    def merge_results(self, original_code, selected_results):\n        \"\"\"\n        Compatibilité avec l'ancienne API.\n        Utilise le MergeAgent existant.\n        \"\"\"\n        if not selected_results:\n            return original_code\n        \n        proposals = []\n        for res in selected_results:\n            proposal = res.get(\"proposal\", \"\")\n            if proposal and proposal != original_code:\n                proposals.append(proposal)\n        \n        # Utiliser la température pour le merge\n        return self.merge_agent.merge(\n            original_code, \n       ",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "74ba021a37679eb9",
    "text": "s.append(proposal)\n        \n        # Utiliser la température pour le merge\n        return self.merge_agent.merge(\n            original_code, \n            proposals, \n            temperature=0.2  # Température basse pour la fusion\n        )\n    \n    def run_patch_and_test(self, code, language, patch=True, test=True):\n        \"\"\"\n        Compatibilité avec l'ancienne API.\n        \"\"\"\n        patch_result = None\n        test_result = None\n\n        if patch:\n            patch_agent = self.agent_instances.get(\"PatchAgent\")\n            if patch_agent:\n                patch_result = patch_agent.apply(code, language=language)\n                code = patch_result[\"proposal\"]\n\n        if test:\n            test_agent = self.agent_instances.get(\"TestAgent\")\n            if test_agent:\n                test_result = test_agent.apply(code, language=language)\n\n        return code, patch_result, test_result\n    \n    def get_available_agents(self):\n        \"\"\"Retourne la liste de tous les agents disponibles\"\"\"\n        return list(self.agent_instances.keys())\n    \n    def get_refactoring_agents(self):\n        \"\"\"Retourne uniquement les agents de refactoring (sans Test et Patch)\"\"\"\n        return [name",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "ddace9012a6d8b36",
    "text": "ys())\n    \n    def get_refactoring_agents(self):\n        \"\"\"Retourne uniquement les agents de refactoring (sans Test et Patch)\"\"\"\n        return [name for name in self.agent_instances.keys() \n                if name not in [\"TestAgent\", \"PatchAgent\", \"MergeAgent\"]]\n\n# Alias pour compatibilité\nOrchestrator = LangGraphOrchestrator",
    "source": "core/langgraph_orchestrator.py"
  },
  {
    "id": "f1f7c8e0151996ed",
    "text": "import openai\nfrom dotenv import load_dotenv\nimport os\n\nclass LLMClient:\n    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n        load_dotenv()\n        self.api_key = os.environ.get(\"OPENAI_API_KEY\")\n        if not self.api_key:\n            raise ValueError(\"OPENAI_API_KEY non définie.\")\n        openai.api_key = self.api_key\n        self.model_name = model_name\n\n    def ask(self, system_prompt, user_prompt):\n        \"\"\"\n        Version compatible OpenAI >=1.0.0\n        \"\"\"\n        response = openai.chat.completions.create(\n            model=self.model_name,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            temperature=0.3,\n            max_tokens=1500\n        )\n        return response.choices[0].message['content']\n",
    "source": "core/llm_client.py"
  },
  {
    "id": "a3f6d1320ef52871",
    "text": "import subprocess\nimport json\nimport time\n\nclass OllamaLLMClient:\n    def __init__(self, model_name=\"qwen2.5-coder:latest\", base_url=\"http://localhost:11434\"):\n        self.model_name = model_name\n        self.base_url = base_url\n    \n    def ask(self, system_prompt, user_prompt, temperature=None, max_tokens=2000):\n        \"\"\"\n        Envoie le prompt au modèle Ollama local avec support de température.\n        \n        Args:\n            system_prompt: Prompt système\n            user_prompt: Prompt utilisateur\n            temperature: Température pour la génération (0.0-1.0)\n            max_tokens: Nombre maximum de tokens à générer\n        \n        Returns:\n            str: Réponse du modèle\n        \"\"\"\n        full_prompt = f\"{system_prompt}\\n\\n{user_prompt}\"\n        \n        try:\n            # Méthode 1: Utiliser l'API REST d'Ollama (recommandée)\n            return self._ask_via_api(full_prompt, temperature, max_tokens)\n        except Exception as e:\n            # Méthode 2: Fallback avec subprocess\n            print(f\"⚠️ API Ollama échouée, fallback subprocess: {e}\")\n            return self._ask_via_subprocess(full_prompt)\n    \n    def _ask_via_api(self, prompt, temperature=None",
    "source": "core/ollama_llm_client.py"
  },
  {
    "id": "115bccb9afc7ed1e",
    "text": " échouée, fallback subprocess: {e}\")\n            return self._ask_via_subprocess(full_prompt)\n    \n    def _ask_via_api(self, prompt, temperature=None, max_tokens=2000):\n        \"\"\"Utilise l'API REST d'Ollama\"\"\"\n        import requests\n        \n        request_data = {\n            \"model\": self.model_name,\n            \"prompt\": prompt,\n            \"stream\": False,\n            \"options\": {\n                \"num_predict\": max_tokens\n            }\n        }\n        \n        # Ajouter la température si spécifiée\n        if temperature is not None:\n            request_data[\"options\"][\"temperature\"] = temperature\n        \n        try:\n            response = requests.post(\n                f\"{self.base_url}/api/generate\",\n                json=request_data,\n                timeout=120  # 2 minutes timeout\n            )\n            response.raise_for_status()\n            result = response.json()\n            return result.get(\"response\", \"\").strip()\n            \n        except requests.exceptions.RequestException as e:\n            raise Exception(f\"Erreur API Ollama: {e}\")\n    \n    def _ask_via_subprocess(self, prompt):\n        \"\"\"Méthode de fallback avec subprocess\"\"\"\n        try:\n           ",
    "source": "core/ollama_llm_client.py"
  },
  {
    "id": "294a35d4d66ee888",
    "text": "(f\"Erreur API Ollama: {e}\")\n    \n    def _ask_via_subprocess(self, prompt):\n        \"\"\"Méthode de fallback avec subprocess\"\"\"\n        try:\n            # Préparer la commande\n            cmd = [\"ollama\", \"run\", self.model_name]\n            \n            process = subprocess.Popen(\n                cmd,\n                stdin=subprocess.PIPE,\n                stdout=subprocess.PIPE,\n                stderr=subprocess.PIPE,\n                text=True,\n                encoding=\"utf-8\"\n            )\n            \n            stdout, stderr = process.communicate(prompt, timeout=60)\n            \n            if process.returncode != 0:\n                error_msg = stderr.strip() if stderr else f\"Code de retour: {process.returncode}\"\n                return f\"Error: {error_msg}\"\n            \n            return stdout.strip()\n            \n        except subprocess.TimeoutExpired:\n            process.kill()\n            return \"Error: Timeout - le modèle a pris trop de temps à répondre\"\n        except Exception as e:\n            return f\"Error: {str(e)}\"\n    \n    def list_models(self):\n        \"\"\"Liste les modèles disponibles localement\"\"\"\n        try:\n            import requests\n            response =",
    "source": "core/ollama_llm_client.py"
  },
  {
    "id": "1da3cd03e866a78c",
    "text": "    \n    def list_models(self):\n        \"\"\"Liste les modèles disponibles localement\"\"\"\n        try:\n            import requests\n            response = requests.get(f\"{self.base_url}/api/tags\")\n            if response.status_code == 200:\n                data = response.json()\n                return [model[\"name\"] for model in data.get(\"models\", [])]\n            return []\n        except:\n            # Fallback avec commande\n            try:\n                result = subprocess.run(\n                    [\"ollama\", \"list\"],\n                    capture_output=True,\n                    text=True\n                )\n                if result.returncode == 0:\n                    lines = result.stdout.strip().split('\\n')[1:]  # Ignorer l'en-tête\n                    models = []\n                    for line in lines:\n                        if line:\n                            parts = line.split()\n                            if parts:\n                                models.append(parts[0])\n                    return models\n                return []\n            except:\n                return []\n    \n    def test_connection(self):\n        \"\"\"Teste la connexion à Ollama\"\"\"\n        try:\n            i",
    "source": "core/ollama_llm_client.py"
  },
  {
    "id": "be571068c131f451",
    "text": "            except:\n                return []\n    \n    def test_connection(self):\n        \"\"\"Teste la connexion à Ollama\"\"\"\n        try:\n            import requests\n            response = requests.get(f\"{self.base_url}/api/tags\", timeout=5)\n            return response.status_code == 200\n        except:\n            return False",
    "source": "core/ollama_llm_client.py"
  },
  {
    "id": "a8062a9ec0a87031",
    "text": "# ==================== core/orchestrator.py ====================\n# Orchestrator unifié avec support de température et nouveaux agents\n\nfrom agents.rename_agent import RenameAgent\nfrom agents.complexity_agent import ComplexityAgent\nfrom agents.duplication_agent import DuplicationAgent\nfrom agents.import_agent import ImportAgent\nfrom agents.long_function_agent import LongFunctionAgent\nfrom agents.merge_agent import MergeAgent\nfrom agents.test_agent import TestAgent\nfrom agents.patch_agent import PatchAgent\nfrom core.temperature_config import TemperatureConfig\n\nclass Orchestrator:\n    def __init__(self, llm):\n        # Instanciation de tous les agents\n        self.agent_instances = {\n            \"RenameAgent\": RenameAgent(llm),\n            \"ComplexityAgent\": ComplexityAgent(llm),\n            \"DuplicationAgent\": DuplicationAgent(llm),\n            \"ImportAgent\": ImportAgent(llm),\n            \"LongFunctionAgent\": LongFunctionAgent(llm),\n            \"TestAgent\": TestAgent(llm),\n            \"PatchAgent\": PatchAgent(llm),\n        }\n        self.merge_agent = MergeAgent(llm)\n        self.temperature_config = TemperatureConfig()\n\n    def run_parallel(self, code, selected_agent_names, language",
    "source": "core/orchestrator.py"
  },
  {
    "id": "566c3db6a83427fa",
    "text": "f.merge_agent = MergeAgent(llm)\n        self.temperature_config = TemperatureConfig()\n\n    def run_parallel(self, code, selected_agent_names, language, temperature_override=None):\n        \"\"\"\n        Exécute les agents de refactoring en parallèle.\n        \n        Args:\n            code: Code source\n            selected_agent_names: Liste des noms d'agents\n            language: Langage de programmation\n            temperature_override: Température à utiliser pour tous les agents (optionnel)\n        \"\"\"\n        results = []\n\n        for name in selected_agent_names:\n            agent = self.agent_instances.get(name)\n            if agent and name not in [\"TestAgent\", \"PatchAgent\", \"MergeAgent\"]:\n                # Déterminer la température à utiliser\n                if temperature_override is not None:\n                    temp_to_use = temperature_override\n                else:\n                    # Utiliser la température optimale de l'agent\n                    temp_to_use = self.temperature_config.get_temperature(name)\n                \n                # Appeler apply() avec le paramètre temperature\n                result = agent.apply(code, language=language, temperature=temp_to_use",
    "source": "core/orchestrator.py"
  },
  {
    "id": "1b13adf4b3d9b256",
    "text": "\n                # Appeler apply() avec le paramètre temperature\n                result = agent.apply(code, language=language, temperature=temp_to_use)\n                results.append(result)\n\n        return results\n\n    def merge_results(self, original_code, selected_results):\n        \"\"\"\n        Fusionne le code original avec les propositions sélectionnées.\n        \"\"\"\n        if not selected_results:\n            return original_code\n        \n        # Extraire les propositions\n        proposals = []\n        merge_temperature = 0.2  # Température basse pour la fusion (précision)\n        \n        for res in selected_results:\n            proposal = res.get(\"proposal\", \"\")\n            if proposal and proposal != original_code:\n                proposals.append(proposal)\n        \n        # Utiliser la température pour le merge\n        return self.merge_agent.merge(\n            original_code, \n            proposals, \n            temperature=merge_temperature\n        )\n    \n    def run_patch_and_test(self, code, language, patch=True, test=True):\n        \"\"\"\n        Applique PatchAgent et TestAgent.\n        \n        Returns:\n            tuple: (code_final, patch_result, test_result)\n     ",
    "source": "core/orchestrator.py"
  },
  {
    "id": "14ea3911af0926cb",
    "text": "rue):\n        \"\"\"\n        Applique PatchAgent et TestAgent.\n        \n        Returns:\n            tuple: (code_final, patch_result, test_result)\n        \"\"\"\n        patch_result = None\n        test_result = None\n\n        # Appliquer le patch si demandé\n        if patch:\n            patch_agent = self.agent_instances.get(\"PatchAgent\")\n            if patch_agent:\n                patch_result = patch_agent.apply(code, language=language)\n                code = patch_result[\"proposal\"]\n\n        # Exécuter les tests si demandé\n        if test:\n            test_agent = self.agent_instances.get(\"TestAgent\")\n            if test_agent:\n                test_result = test_agent.apply(code, language=language)\n\n        return code, patch_result, test_result\n    \n    def get_available_agents(self):\n        \"\"\"Retourne la liste de tous les agents disponibles\"\"\"\n        return list(self.agent_instances.keys())\n    \n    def get_refactoring_agents(self):\n        \"\"\"Retourne uniquement les agents de refactoring (sans Test et Patch)\"\"\"\n        return [name for name in self.agent_instances.keys() \n                if name not in [\"TestAgent\", \"PatchAgent\", \"MergeAgent\"]]",
    "source": "core/orchestrator.py"
  },
  {
    "id": "b820b4f1c62630ff",
    "text": "e for name in self.agent_instances.keys() \n                if name not in [\"TestAgent\", \"PatchAgent\", \"MergeAgent\"]]",
    "source": "core/orchestrator.py"
  },
  {
    "id": "2a328ca45f167f23",
    "text": "class TemperatureConfig:\n    \"\"\"\n    Configuration optimisée de la température pour chaque type d'agent.\n    \"\"\"\n    \n    OPTIMAL_TEMPERATURES = {\n        \"RenameAgent\": {\n            \"default\": 0.1,\n            \"description\": \"Renommage nécessite de la précision et de la cohérence\",\n            \"range\": (0.1, 0.3),\n            \"icon\": \"🏷️\"\n        },\n        \"ImportAgent\": {\n            \"default\": 0.2,\n            \"description\": \"Optimisation d'imports est une tâche mécanique\",\n            \"range\": (0.1, 0.4),\n            \"icon\": \"📦\"\n        },\n        \"ComplexityAgent\": {\n            \"default\": 0.4,\n            \"description\": \"Simplification algorithmique nécessite de la créativité\",\n            \"range\": (0.3, 0.6),\n            \"icon\": \"🧠\"\n        },\n        \"DuplicationAgent\": {\n            \"default\": 0.5,\n            \"description\": \"Factorisation de code nécessite de l'innovation\",\n            \"range\": (0.4, 0.7),\n            \"icon\": \"📋\"\n        },\n        \"LongFunctionAgent\": {\n            \"default\": 0.3,\n            \"description\": \"Découpage de fonctions nécessite un bon équilibre\",\n            \"range\": (0.2, 0.5),\n            \"icon\": \"✂️\"\n        },\n        \"MergeAgent\": {\n ",
    "source": "core/temperature_config.py"
  },
  {
    "id": "f329296b1fe30a87",
    "text": "\": \"Découpage de fonctions nécessite un bon équilibre\",\n            \"range\": (0.2, 0.5),\n            \"icon\": \"✂️\"\n        },\n        \"MergeAgent\": {\n            \"default\": 0.2,\n            \"description\": \"Fusion nécessite de la précision pour éviter les conflits\",\n            \"range\": (0.1, 0.3),\n            \"icon\": \"🔄\"\n        },\n        \"PatchAgent\": {\n            \"default\": 0.1,\n            \"description\": \"Nettoyage nécessite de la rigueur\",\n            \"range\": (0.1, 0.3),\n            \"icon\": \"🩹\"\n        }\n    }\n    \n    # Agents spéciaux (température non applicable ou différente)\n    SPECIAL_AGENTS = {\n        \"TestAgent\": {\n            \"description\": \"Validation automatique avec outils statiques\",\n            \"icon\": \"🧪\",\n            \"has_temperature\": False,\n            \"note\": \"Utilise la température pour la correction automatique (0.1)\"\n        }\n    }\n    \n    @classmethod\n    def get_temperature(cls, agent_name):\n        \"\"\"Retourne la température optimale pour un agent\"\"\"\n        if agent_name in cls.SPECIAL_AGENTS:\n            special = cls.SPECIAL_AGENTS[agent_name]\n            if special.get(\"has_temperature\", True):\n                return special.get(\"default\", 0.3)",
    "source": "core/temperature_config.py"
  },
  {
    "id": "07f0271f740610e5",
    "text": "      special = cls.SPECIAL_AGENTS[agent_name]\n            if special.get(\"has_temperature\", True):\n                return special.get(\"default\", 0.3)\n            return None  # Pas de température\n        \n        agent_config = cls.OPTIMAL_TEMPERATURES.get(agent_name, {})\n        return agent_config.get(\"default\", 0.3)\n    \n    @classmethod\n    def get_all_configs(cls):\n        \"\"\"Retourne toutes les configurations\"\"\"\n        configs = {}\n        configs.update(cls.OPTIMAL_TEMPERATURES)\n        configs.update(cls.SPECIAL_AGENTS)\n        return configs\n    \n    @classmethod\n    def get_agent_info(cls, agent_name):\n        \"\"\"Retourne toutes les informations sur un agent\"\"\"\n        if agent_name in cls.OPTIMAL_TEMPERATURES:\n            info = cls.OPTIMAL_TEMPERATURES[agent_name].copy()\n            info[\"has_temperature\"] = True\n            return info\n        elif agent_name in cls.SPECIAL_AGENTS:\n            info = cls.SPECIAL_AGENTS[agent_name].copy()\n            info[\"has_temperature\"] = info.get(\"has_temperature\", True)\n            return info\n        return {\n            \"description\": \"Agent inconnu\", \n            \"icon\": \"❓\", \n            \"has_temperature\": True,\n            ",
    "source": "core/temperature_config.py"
  },
  {
    "id": "89c372caf45e6fa2",
    "text": " return info\n        return {\n            \"description\": \"Agent inconnu\", \n            \"icon\": \"❓\", \n            \"has_temperature\": True,\n            \"default\": 0.3\n        }",
    "source": "core/temperature_config.py"
  },
  {
    "id": "1ba50f4534bc8bee",
    "text": "from core.graphrag_retriever import GraphRAGRetriever\n\nr = GraphRAGRetriever()\npack = r.retrieve(\"TemperatureConfig and LangGraphOrchestrator refactoring context\", k_seeds=4, hops=2, max_chunks=5)\n\nprint(\"Symbols:\", pack.get(\"symbols\"))\nprint(\"Seeds:\", pack.get(\"seeds\"))\nprint(\"\\n--- CONTEXT ---\\n\")\nprint(r.format_context(pack))",
    "source": "core/test_graphrag.py"
  },
  {
    "id": "9f4502ece8f613a2",
    "text": "\"\"\"\nConstruction du graphe LangGraph pour le refactoring.\n\"\"\"\n\nfrom typing import Dict, Any, Callable\nfrom langgraph.graph import StateGraph, END\nfrom .workflow_state import RefactorState\nfrom .workflow_nodes import *\n\ndef build_refactor_graph(orchestrator) -> StateGraph:\n    \"\"\"\n    Construit le graphe de refactoring intelligent.\n    \n    Args:\n        orchestrator: Instance de LangGraphOrchestrator avec les agents\n        \n    Returns:\n        StateGraph: Graphe compilé prêt à l'exécution\n    \"\"\"\n    # Créer le graphe\n    graph = StateGraph(RefactorState)\n    \n    # Ajouter les nœuds\n    graph.add_node(\"initialize\", initialize_node)\n    graph.add_node(\"analyze_issues\", analyze_issues_node)\n    graph.add_node(\"merge_results\", merge_results_node)\n    graph.add_node(\"apply_patch\", apply_patch_node)\n    graph.add_node(\"run_tests\", run_tests_node)\n    graph.add_node(\"finalize\", finalize_node)\n    graph.add_node(\"handle_error\", handle_error_node)\n    \n    # Ajouter des nœuds dynamiques pour chaque agent\n    # Ces nœuds seront ajoutés à la volée lors de l'exécution\n    def create_agent_executor(agent_name: str):\n        \"\"\"Crée une fonction qui exécute un agent spécifique\"\"\"\n        def",
    "source": "core/workflow_graph.py"
  },
  {
    "id": "33779a0340e2ec97",
    "text": " volée lors de l'exécution\n    def create_agent_executor(agent_name: str):\n        \"\"\"Crée une fonction qui exécute un agent spécifique\"\"\"\n        def execute_agent(state: RefactorState) -> RefactorState:\n            return execute_refactoring_agent_node(state, agent_name)\n        return execute_agent\n    \n    # Définir le flux principal\n    graph.set_entry_point(\"initialize\")\n    graph.add_edge(\"initialize\", \"analyze_issues\")\n    \n    # Après l'analyse, on décide dynamiquement quel agent exécuter\n    graph.add_conditional_edges(\n        \"analyze_issues\",\n        decide_next_agent_node,\n        {\n            \"execute_refactoring_agent\": \"execute_refactoring_agent\",\n            \"merge_results\": \"merge_results\"\n        }\n    )\n    \n    # Après chaque agent, on redécide\n    # Note: Les nœuds d'agents seront ajoutés dynamiquement\n    \n    # Suite du workflow\n    graph.add_edge(\"merge_results\", \"apply_patch\")\n    graph.add_edge(\"apply_patch\", \"run_tests\")\n    graph.add_edge(\"run_tests\", \"finalize\")\n    graph.add_edge(\"finalize\", END)\n    \n    # Gestion d'erreurs\n    graph.add_edge(\"handle_error\", END)\n    \n    return graph\n\ndef compile_graph(orchestrator) -> StateGraph:\n    \"\"\"\n    Comp",
    "source": "core/workflow_graph.py"
  },
  {
    "id": "20ab28a0719f4583",
    "text": "    # Gestion d'erreurs\n    graph.add_edge(\"handle_error\", END)\n    \n    return graph\n\ndef compile_graph(orchestrator) -> StateGraph:\n    \"\"\"\n    Compile le graphe final avec tous les agents.\n    \n    Args:\n        orchestrator: Instance de LangGraphOrchestrator\n        \n    Returns:\n        StateGraph: Graphe compilé prêt à l'utilisation\n    \"\"\"\n    graph = build_refactor_graph(orchestrator)\n    \n    # Ajouter un nœud pour chaque agent de refactoring\n    for agent_name in orchestrator.get_refactoring_agents():\n        # Créer une fonction qui exécute cet agent avec l'orchestrateur\n        def create_agent_executor(name: str):\n            def executor(state: RefactorState) -> RefactorState:\n                # Récupérer la température configurée\n                temperature = state.get(\"temperature_config\").get_temperature(name)\n                \n                # Exécuter l'agent\n                agent = orchestrator.agent_instances.get(name)\n                if agent:\n                    result = agent.apply(\n                        state[\"current_code\"],\n                        state[\"language\"],\n                        temperature=temperature\n                    )\n                   ",
    "source": "core/workflow_graph.py"
  },
  {
    "id": "00287e1d20f2b47b",
    "text": "[\"current_code\"],\n                        state[\"language\"],\n                        temperature=temperature\n                    )\n                    \n                    # Ajouter le résultat\n                    from .workflow_state import AgentResult\n                    agent_result = AgentResult(\n                        name=result[\"name\"],\n                        analysis=result.get(\"analysis\", []),\n                        proposal=result.get(\"proposal\", \"\"),\n                        temperature_used=result.get(\"temperature_used\")\n                    )\n                    \n                    state[\"agent_results\"].append(agent_result)\n                    state[\"issues_detected\"].extend(result.get(\"analysis\", []))\n                    \n                    # Mettre à jour le code courant avec la proposition\n                    state[\"current_code\"] = result.get(\"proposal\", state[\"current_code\"])\n                \n                return state\n            return executor\n        \n        # Ajouter le nœud au graphe\n        graph.add_node(f\"agent_{agent_name}\", create_agent_executor(agent_name))\n    \n    return graph.compile()",
    "source": "core/workflow_graph.py"
  },
  {
    "id": "ea694cc79acf6971",
    "text": "de(f\"agent_{agent_name}\", create_agent_executor(agent_name))\n    \n    return graph.compile()",
    "source": "core/workflow_graph.py"
  },
  {
    "id": "ea3a2d3f1ce3e0fd",
    "text": "\"\"\"\nNœuds pour le workflow LangGraph de refactoring.\nChaque nœud est une fonction qui prend l'état en entrée et le modifie.\n\"\"\"\n\nfrom typing import Dict, Any\nfrom .workflow_state import RefactorState\nimport time\n\ndef initialize_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud d'initialisation : prépare l'état\"\"\"\n    print(f\"🔧 Initialisation du workflow pour {state['language']}\")\n    \n    state[\"current_code\"] = state[\"original_code\"]\n    state[\"agent_results\"] = []\n    state[\"issues_detected\"] = []\n    state[\"history\"] = []\n    state[\"status\"] = \"analyzing\"\n    state[\"metrics\"] = {\n        \"start_time\": time.time(),\n        \"agents_executed\": 0,\n        \"issues_found\": 0,\n        \"code_length_original\": len(state[\"original_code\"])\n    }\n    \n    # Enregistrer dans l'historique\n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"initialize\",\n        \"message\": f\"Workflow démarré avec {len(state['selected_agents'])} agents sélectionnés\"\n    })\n    \n    return state\n\ndef analyze_issues_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud d'analyse : détecte les problèmes dans le code\"\"\"\n    print(\"🔍 Analyse des problèmes...\")\n    \n    # Ici, ",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "1afb48ce6c16aa9a",
    "text": "efactorState) -> RefactorState:\n    \"\"\"Nœud d'analyse : détecte les problèmes dans le code\"\"\"\n    print(\"🔍 Analyse des problèmes...\")\n    \n    # Ici, on pourrait ajouter une analyse heuristique pour décider\n    # quels agents exécuter en priorité, mais pour maintenant,\n    # on exécutera simplement tous les agents sélectionnés\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"analyze\",\n        \"message\": f\"Analyse terminée - {len(state['selected_agents'])} agents à exécuter\"\n    })\n    \n    return state\n\ndef execute_refactoring_agent_node(state: RefactorState, agent_name: str) -> RefactorState:\n    \"\"\"Nœud d'exécution d'un agent de refactoring spécifique\"\"\"\n    print(f\"⚡ Exécution de {agent_name}...\")\n    \n    # Cette fonction serait appelée pour chaque agent\n    # Dans l'implémentation finale, on utiliserait les agents existants\n    \n    state[\"current_agent\"] = agent_name\n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"execute_agent\",\n        \"agent\": agent_name\n    })\n    \n    return state\n\ndef decide_next_agent_node(state: RefactorState) -> Dict[str, Any]:\n    \"\"\"\n    Nœud de décision : choisit le prochain",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "677a278cb14f4275",
    "text": "e\n    })\n    \n    return state\n\ndef decide_next_agent_node(state: RefactorState) -> Dict[str, Any]:\n    \"\"\"\n    Nœud de décision : choisit le prochain agent à exécuter.\n    Retourne le nom du prochain nœud à exécuter.\n    \"\"\"\n    # Logique de décision intelligente\n    executed_agents = [r.name for r in state.get(\"agent_results\", [])]\n    remaining_agents = [\n        agent for agent in state[\"selected_agents\"] \n        if agent not in executed_agents \n        and agent not in [\"TestAgent\", \"PatchAgent\", \"MergeAgent\"]\n    ]\n    \n    if remaining_agents:\n        # Exécuter le prochain agent\n        next_agent = remaining_agents[0]\n        return {\"next\": \"execute_refactoring_agent\", \"agent\": next_agent}\n    \n    # Tous les agents de refactoring sont terminés\n    return {\"next\": \"merge_results\"}\n\ndef merge_results_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud de fusion des résultats des agents\"\"\"\n    print(\"🔄 Fusion des résultats...\")\n    \n    # Pour l'instant, on garde le code tel quel\n    # Dans l'implémentation finale, on utiliserait le MergeAgent\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"merge\",\n        \"message\": \"Fusion des",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "9c98b89892a7885b",
    "text": "iliserait le MergeAgent\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"merge\",\n        \"message\": \"Fusion des propositions d'agents\"\n    })\n    \n    state[\"status\"] = \"patching\"\n    return state\n\ndef apply_patch_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud d'application du PatchAgent\"\"\"\n    if not state.get(\"auto_patch\", True):\n        print(\"⏭️ PatchAgent désactivé\")\n        return state\n    \n    print(\"🩹 Application du PatchAgent...\")\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"patch\",\n        \"message\": \"PatchAgent appliqué\"\n    })\n    \n    state[\"status\"] = \"testing\"\n    return state\n\ndef run_tests_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud d'exécution du TestAgent\"\"\"\n    if not state.get(\"auto_test\", True):\n        print(\"⏭️ TestAgent désactivé\")\n        return state\n    \n    print(\"🧪 Exécution du TestAgent...\")\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"test\",\n        \"message\": \"TestAgent exécuté\"\n    })\n    \n    state[\"status\"] = \"completed\"\n    return state\n\ndef finalize_node(state: RefactorState) -> RefactorState:\n    ",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "906b917a9ed5e4a0",
    "text": "e\": \"TestAgent exécuté\"\n    })\n    \n    state[\"status\"] = \"completed\"\n    return state\n\ndef finalize_node(state: RefactorState) -> RefactorState:\n    \"\"\"Nœud de finalisation : calcule les métriques finales\"\"\"\n    print(\"✅ Finalisation du workflow...\")\n    \n    # Calculer les métriques finales\n    execution_time = time.time() - state[\"metrics\"][\"start_time\"]\n    state[\"metrics\"][\"execution_time\"] = execution_time\n    state[\"metrics\"][\"agents_executed\"] = len(state.get(\"agent_results\", []))\n    state[\"metrics\"][\"code_length_final\"] = len(state.get(\"current_code\", \"\"))\n    \n    # Définir le code final\n    state[\"final_code\"] = state.get(\"current_code\", state[\"original_code\"])\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"finalize\",\n        \"message\": f\"Workflow terminé en {execution_time:.2f}s\"\n    })\n    \n    return state\n\ndef handle_error_node(state: RefactorState, error: Exception) -> RefactorState:\n    \"\"\"Nœud de gestion d'erreur\"\"\"\n    print(f\"❌ Erreur dans le workflow : {error}\")\n    \n    state[\"error\"] = str(error)\n    state[\"status\"] = \"failed\"\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"erro",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "6191fac29b7ca3fc",
    "text": "tate[\"error\"] = str(error)\n    state[\"status\"] = \"failed\"\n    \n    state[\"history\"].append({\n        \"timestamp\": time.time(),\n        \"action\": \"error\",\n        \"message\": str(error)\n    })\n    \n    return state",
    "source": "core/workflow_nodes.py"
  },
  {
    "id": "8c26b6845d2cdd83",
    "text": "\"\"\"\nÉtat partagé pour le workflow LangGraph de refactoring.\n\"\"\"\n\nfrom typing import TypedDict, List, Dict, Optional, Any\nfrom dataclasses import dataclass\n\n@dataclass\nclass AgentResult:\n    \"\"\"Résultat d'un agent de refactoring\"\"\"\n    name: str\n    analysis: List[str]\n    proposal: str\n    temperature_used: Optional[float] = None\n\nclass RefactorState(TypedDict):\n    \"\"\"\n    État partagé pour tout le workflow de refactoring.\n    Cet objet est passé entre tous les nœuds du graphe.\n    \"\"\"\n    # Entrée\n    original_code: str\n    language: str\n    \n    # État courant\n    current_code: str\n    current_agent: Optional[str]\n    \n    # Résultats et historique\n    agent_results: List[AgentResult]\n    issues_detected: List[Dict[str, Any]]\n    history: List[Dict[str, Any]]\n    \n    # Configuration\n    selected_agents: List[str]\n    temperature_config: Any  # TemperatureConfig\n    auto_patch: bool\n    auto_test: bool\n    \n    # Métriques\n    metrics: Dict[str, Any]\n    \n    # Erreurs et statut\n    error: Optional[str]\n    status: str  # \"initialized\", \"analyzing\", \"refactoring\", \"patching\", \"testing\", \"completed\", \"failed\"\n    \n    # Résultats finaux\n    patch_result: Optional[Dict[str, Any]]\n",
    "source": "core/workflow_state.py"
  },
  {
    "id": "56c48b290337b548",
    "text": "zed\", \"analyzing\", \"refactoring\", \"patching\", \"testing\", \"completed\", \"failed\"\n    \n    # Résultats finaux\n    patch_result: Optional[Dict[str, Any]]\n    test_result: Optional[Dict[str, Any]]\n    final_code: Optional[str]",
    "source": "core/workflow_state.py"
  },
  {
    "id": "dfbeadd102f5c366",
    "text": "# agents/base_agent.py\n\nfrom __future__ import annotations\n\nimport inspect\n\n# GraphRAG: import optionnel (fallback si le module n'existe pas)\ntry:\n    from core.graphrag_retriever import GraphRAGRetriever\nexcept Exception:\n    GraphRAGRetriever = None\n\n\nclass BaseAgent:\n    \"\"\"\n    Classe de base pour tous les agents avec support de température rétrocompatible\n    + GraphRAG (optionnel) pour enrichir le contexte.\n\n    GraphRAG est activé uniquement pour les agents de refactoring structurel/sémantique.\n    \"\"\"\n\n    # ✅ RAG seulement pour ces 5 agents\n    GRAPHRAG_ENABLED_AGENTS = {\n        \"RenameAgent\",\n        \"ComplexityAgent\",\n        \"DuplicationAgent\",\n        \"ImportAgent\",\n        \"LongFunctionAgent\",\n    }\n\n    def __init__(self, llm, name: str = \"Agent inconnu\", use_graphrag: bool = True):\n        self.llm = llm\n        self.name = name\n        self.use_graphrag = use_graphrag\n\n    def analyze(self, code, language):\n        \"\"\"\n        Analyse le code et retourne une liste de problèmes ou suggestions.\n        Doit être surchargée par chaque agent.\n        \"\"\"\n        return []\n\n    def build_prompt(self, code, language):\n        \"\"\"Méthode par défaut pour construire le pro",
    "source": "agents/base_agent.py"
  },
  {
    "id": "4182857f25a452e5",
    "text": "rgée par chaque agent.\n        \"\"\"\n        return []\n\n    def build_prompt(self, code, language):\n        \"\"\"Méthode par défaut pour construire le prompt (peut être surchargée)\"\"\"\n        return f\"Refactor the following {language} code for {self.name} improvements.\"\n\n    def _should_use_graphrag(self) -> bool:\n        \"\"\"\n        Décide automatiquement si GraphRAG doit être utilisé pour cet agent.\n        \"\"\"\n        return (\n            self.use_graphrag\n            and self.name in self.GRAPHRAG_ENABLED_AGENTS\n            and GraphRAGRetriever is not None\n        )\n\n    def _inject_graphrag(self, system_prompt: str, code: str, language: str) -> str:\n        \"\"\"\n        Injecte un contexte GraphRAG dans le prompt système.\n        Si GraphRAG n'est pas disponible, non autorisé pour cet agent, ou échoue,\n        retourne system_prompt inchangé.\n        \"\"\"\n        if not self._should_use_graphrag():\n            return system_prompt\n\n        try:\n            retriever = GraphRAGRetriever()\n            query = (\n                f\"Refactoring context for agent={self.name}, language={language}. \"\n                f\"Project conventions, related modules/classes/functions, dependencies. \"\n ",
    "source": "agents/base_agent.py"
  },
  {
    "id": "fd7611b706e93a00",
    "text": "ring context for agent={self.name}, language={language}. \"\n                f\"Project conventions, related modules/classes/functions, dependencies. \"\n                f\"Code snippet: {code[:600]}\"\n            )\n\n            pack = retriever.retrieve(query=query, k_seeds=4, hops=2, max_chunks=6)\n            context_txt = retriever.format_context(pack).strip()\n\n            if not context_txt:\n                return system_prompt\n\n            # Debug utile (tu peux le garder)\n            print(f\"🔎 GraphRAG injecté pour {self.name}\")\n\n            return (\n                system_prompt\n                + \"\\n\\n\"\n                + context_txt\n                + \"\\n\\n\"\n                + \"### Usage Rules\\n\"\n                + \"- Use retrieved context ONLY if relevant.\\n\"\n                + \"- Preserve exact behavior and public APIs.\\n\"\n                + \"- If context conflicts with code semantics, prefer code semantics.\\n\"\n            )\n        except Exception as e:\n            # Fallback silencieux (mais log léger utile pour debug)\n            print(f\"⚠️ GraphRAG ignoré pour {self.name}: {e}\")\n            return system_prompt\n\n    def apply(self, code, language, temperature=None):\n        \"\"\"\n ",
    "source": "agents/base_agent.py"
  },
  {
    "id": "0c08df243a93709d",
    "text": "nt(f\"⚠️ GraphRAG ignoré pour {self.name}: {e}\")\n            return system_prompt\n\n    def apply(self, code, language, temperature=None):\n        \"\"\"\n        Applique l'analyse sur le code.\n\n        Args:\n            code: Code source\n            language: Langage de programmation\n            temperature: Température LLM (optionnel, rétrocompatible)\n\n        Returns:\n            dict: Résultat standardisé\n        \"\"\"\n        analysis = self.analyze(code, language)\n\n        if analysis:\n            # Vérifier si la méthode llm.ask supporte temperature\n            llm_method = getattr(self.llm, \"ask\", None)\n            if not callable(llm_method):\n                raise AttributeError(f\"LLM client {self.llm} n'a pas de méthode 'ask'\")\n\n            # Construire le prompt (peut être surchargé)\n            prompt = self.build_prompt(code, language)\n\n            # ✅ Injecter GraphRAG seulement pour les agents autorisés\n            prompt = self._inject_graphrag(prompt, code, language)\n\n            try:\n                # Essayer d'appeler avec température si supporté\n                if temperature is not None:\n                    sig = inspect.signature(self.llm.ask)\n                    par",
    "source": "agents/base_agent.py"
  },
  {
    "id": "876c06449bb76c9b",
    "text": " température si supporté\n                if temperature is not None:\n                    sig = inspect.signature(self.llm.ask)\n                    params = sig.parameters\n\n                    if \"temperature\" in params:\n                        proposal = self.llm.ask(\n                            system_prompt=prompt,\n                            user_prompt=code,\n                            temperature=temperature\n                        )\n                    else:\n                        # Fallback sans température\n                        proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n                else:\n                    proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n\n            except Exception as e:\n                print(f\"⚠️ Erreur LLM pour {self.name}: {e}\")\n                proposal = code\n        else:\n            proposal = code\n\n        result = {\n            \"name\": self.name,\n            \"analysis\": analysis,\n            \"proposal\": proposal\n        }\n\n        if temperature is not None:\n            result[\"temperature_used\"] = temperature\n\n        return result",
    "source": "agents/base_agent.py"
  },
  {
    "id": "01647482ed7f44fe",
    "text": ":\n            result[\"temperature_used\"] = temperature\n\n        return result",
    "source": "agents/base_agent.py"
  },
  {
    "id": "67446de9e97186b3",
    "text": "from agents.base_agent import BaseAgent\n\n\nclass ComplexityAgent(BaseAgent):\n    def __init__(self, llm):\n        super().__init__(llm, name=\"ComplexityAgent\")\n\n    # def build_prompt(self, code, language):\n    #     return (\n    #         f\"Analyse ce code {language} et propose un refactoring pour réduire la complexité algorithmique. \"\n    #         \"Si possible, transforme les boucles imbriquées ou opérations coûteuses pour améliorer l'efficacité. \"\n    #         \"Retourne uniquement le code refactoré.\"\n    #     )\n\n    def build_prompt(self, code, language):\n        return f\"\"\"You are an autonomous AI code-refactoring agent specialized in Python. Given Python source code, detect complexity-related code smells and refactor the code to reduce complexity while preserving identical semantics.\n\n### Complexity Smells to Detect\n- High cyclomatic or cognitive complexity\n- Deep or unnecessary nesting\n- Overly long functions or methods\n- Mixed responsibilities within a single unit\n- Complex or duplicated conditional and boolean logic\n- Repeated control-flow patterns\n- Implicit or hidden control flow\n\n### Semantic Preservation Constraints (Mandatory)\n- Preserve exact behavior for all inputs",
    "source": "agents/complexity_agent.py"
  },
  {
    "id": "6abc61c640ce71ed",
    "text": "ed control-flow patterns\n- Implicit or hidden control flow\n\n### Semantic Preservation Constraints (Mandatory)\n- Preserve exact behavior for all inputs and edge cases\n- Do not change return values, side effects, raised exceptions, or execution order\n- Preserve short-circuit logic, mutation timing, and evaluation order\n- Do not change public APIs or function signatures\n- Preserve logging, I/O, randomness, time usage, and global or shared state\n- If a refactor risks semantic change, do not apply it\n\n### Required Output\n1. Detected complexity code smells with location and brief rationale\n2. Fully refactored Python code in a single code block\n3. Short justification explaining why semantics are unchanged\n\"\"\"\n\n    def analyze(self, code, language):\n        # Analyse simplifiée: détecte les boucles imbriquées\n        nested_loops = [line for line in code.splitlines() if \"for\" in line or \"while\" in line]\n        return nested_loops\n\n    def apply(self, code, language, temperature=None):\n        return super().apply(code, language, temperature)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"from agents.base_agent import BaseAgent\n\nclass Complexi",
    "source": "agents/complexity_agent.py"
  },
  {
    "id": "829deb00a5d88f50",
    "text": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"\"\"from agents.base_agent import BaseAgent\n\nclass ComplexityAgent(BaseAgent):\n    def __init__(self, llm):\n        self.llm = llm\n        self.name = \"ComplexityAgent\"\n\n    # def build_prompt(self, code, language):\n    #     return (\n    #         f\"Analyse ce code {language} et propose un refactoring pour réduire la complexité algorithmique. \"\n    #         \"Si possible, transforme les boucles imbriquées ou opérations coûteuses pour améliorer l'efficacité. \"\n    #         \"Retourne uniquement le code refactoré.\"\n    #     )\n    def build_prompt(self, code, language):\n     return f\"\"\"\"\"\"You are an autonomous AI code-refactoring agent specialized in Python. Given Python source code, detect complexity-related code smells and refactor the code to reduce complexity while preserving identical semantics.\n\n            ### Complexity Smells to Detect\n            - High cyclomatic or cognitive complexity\n            - Deep or unnecessary nesting\n            - Overly long functions or methods\n            - Mixed responsibilities within a single unit\n            - Complex or duplicated conditional and ",
    "source": "agents/complexity_agent.py"
  },
  {
    "id": "110e4279d6a5ead9",
    "text": "     - Overly long functions or methods\n            - Mixed responsibilities within a single unit\n            - Complex or duplicated conditional and boolean logic\n            - Repeated control-flow patterns\n            - Implicit or hidden control flow\n\n            ### Semantic Preservation Constraints (Mandatory)\n            - Preserve exact behavior for all inputs and edge cases\n            - Do not change return values, side effects, raised exceptions, or execution order\n            - Preserve short-circuit logic, mutation timing, and evaluation order\n            - Do not change public APIs or function signatures\n            - Preserve logging, I/O, randomness, time usage, and global or shared state\n            - If a refactor risks semantic change, do not apply it\n\n            ### Required Output\n            1. Detected complexity code smells with location and brief rationale\n            2. Fully refactored Python code in a single code block\n            3. Short justification explaining why semantics are unchanged\"\"\"\n\"\"\"\n\n\n   def analyze(self, code):\n        # Analyse simplifiée: détecte les boucles imbriquées\n        nested_loops = [line for line in code.splitlines() if \"for",
    "source": "agents/complexity_agent.py"
  },
  {
    "id": "512bd759fb014dec",
    "text": "f analyze(self, code):\n        # Analyse simplifiée: détecte les boucles imbriquées\n        nested_loops = [line for line in code.splitlines() if \"for\" in line or \"while\" in line]\n        return nested_loops\n    def apply(self, code, language, temperature=None):\n        analysis = self.analyze(code)\n        if analysis:\n            prompt = self.build_prompt(code, language)\n            if temperature is not None:\n                proposal = self.llm.ask(\n                    system_prompt=prompt,\n                    user_prompt=code,\n                    temperature=temperature\n                )\n            else:\n                proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        else:\n            proposal = code\n        return {\n            \"name\": self.name, \n            \"analysis\": analysis, \n            \"proposal\": proposal,\n            \"temperature_used\": temperature\n        }\"\"\"",
    "source": "agents/complexity_agent.py"
  },
  {
    "id": "b84f79a55dc88778",
    "text": "from agents.base_agent import BaseAgent\n\nclass DuplicationAgent(BaseAgent):\n    \"\"\"\n    Agent qui détecte le code dupliqué et propose de le factoriser.\n    \"\"\"\n    def __init__(self, llm):\n        super().__init__(llm, name=\"DuplicationAgent\")\n\n    def analyze(self, code, language):\n        # Ici, on laisse le LLM détecter les duplications complexes\n        prompt = (\n            f\"Analyze the following {language} code and find duplicated code blocks \"\n            \"that can be refactored into functions or loops.\"\n        )\n        return [prompt]  # On retourne le prompt comme analyse initiale\n\n    def apply(self, code, language, temperature=None):\n        analysis = self.analyze(code, language)\n        prompt = (\n            f\"Refactor the following {language} code by reducing duplication. \"\n            \"Keep functionality unchanged.\"\n        )\n        if temperature is not None:\n            proposal = self.llm.ask(\n                system_prompt=prompt,\n                user_prompt=code,\n                temperature=temperature\n            )\n        else:\n            proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        return {\n            \"name\": self.name, \n    ",
    "source": "agents/duplication_agent.py"
  },
  {
    "id": "f2b7aaee29cc9874",
    "text": "     )\n        else:\n            proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        return {\n            \"name\": self.name, \n            \"analysis\": analysis, \n            \"proposal\": proposal,\n            \"temperature_used\": temperature\n        }",
    "source": "agents/duplication_agent.py"
  },
  {
    "id": "6bdfc401d39ceff8",
    "text": "from agents.base_agent import BaseAgent\nimport re\n\nclass ImportAgent(BaseAgent):\n    \"\"\"\n    Agent qui détecte et propose d'optimiser les imports inutilisés ou dupliqués.\n    \"\"\"\n    def __init__(self, llm):\n        super().__init__(llm, name=\"ImportAgent\")\n\n    def analyze(self, code, language):\n        if language == \"Python\":\n            imports = re.findall(r'^\\s*(import .+|from .+ import .+)', code, flags=re.MULTILINE)\n            used_imports = []\n            for imp in imports:\n                name_match = re.findall(r'import (\\w+)', imp)\n                for name in name_match:\n                    if name in code:\n                        used_imports.append(imp)\n            unused_imports = list(set(imports) - set(used_imports))\n            return unused_imports\n        else:\n            return [\"LLM import analysis needed\"]\n\n    def apply(self, code, language, temperature=None):\n        analysis = self.analyze(code, language)\n        if analysis:\n            prompt = (\n                f\"Refactor the following {language} code by removing unused imports: {analysis}. \"\n                \"Keep functionality unchanged.\"\n            )\n            if temperature is not None:\n       ",
    "source": "agents/import_agent.py"
  },
  {
    "id": "83c694627d68b71e",
    "text": "y removing unused imports: {analysis}. \"\n                \"Keep functionality unchanged.\"\n            )\n            if temperature is not None:\n                proposal = self.llm.ask(\n                    system_prompt=prompt,\n                    user_prompt=code,\n                    temperature=temperature\n                )\n            else:\n                proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        else:\n            proposal = code\n        return {\n            \"name\": self.name, \n            \"analysis\": analysis, \n            \"proposal\": proposal,\n            \"temperature_used\": temperature\n        }",
    "source": "agents/import_agent.py"
  },
  {
    "id": "86a9619e6ba923f2",
    "text": "from agents.base_agent import BaseAgent\nimport re\n\nclass LongFunctionAgent(BaseAgent):\n    \"\"\"\n    Agent qui détecte les fonctions trop longues et propose des refactorings.\n    \"\"\"\n    def __init__(self, llm):\n        super().__init__(llm, name=\"LongFunctionAgent\")\n\n    def analyze(self, code, language):\n        if language == \"Python\":\n            functions = re.findall(r'def (\\w+)\\(.*\\):', code)\n            long_functions = []\n            lines = code.splitlines()\n            for func in functions:\n                start = next((i for i, line in enumerate(lines) if f'def {func}' in line), None)\n                if start is not None:\n                    # On compte les lignes jusqu'à la prochaine fonction ou fin du code\n                    end = next((i for i, line in enumerate(lines[start+1:], start+start+1) if line.strip().startswith(\"def \")), len(lines))\n                    if end - start > 20:  # seuil de 20 lignes pour considérer \"long\"\n                        long_functions.append(func)\n            return long_functions\n        else:\n            return [\"LLM long function analysis needed\"]\n\n    def apply(self, code, language, temperature=None):\n        analysis = self.analyze(",
    "source": "agents/long_function_agent.py"
  },
  {
    "id": "305f394b504880de",
    "text": "lse:\n            return [\"LLM long function analysis needed\"]\n\n    def apply(self, code, language, temperature=None):\n        analysis = self.analyze(code, language)\n        if analysis:\n            prompt = (\n                f\"Refactor the following {language} code. Functions {analysis} are too long. \"\n                \"Split them into smaller functions without changing behavior.\"\n            )\n            if temperature is not None:\n                proposal = self.llm.ask(\n                    system_prompt=prompt,\n                    user_prompt=code,\n                    temperature=temperature\n                )\n            else:\n                proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        else:\n            proposal = code\n        return {\n            \"name\": self.name, \n            \"analysis\": analysis, \n            \"proposal\": proposal,\n            \"temperature_used\": temperature\n        }",
    "source": "agents/long_function_agent.py"
  },
  {
    "id": "4a8e2060d41f2d62",
    "text": "# agents/merge_agent.py\n\nclass MergeAgent:\n    def __init__(self, llm):\n        self.llm = llm\n        self.name = \"MergeAgent\"\n\n    def merge(self, original_code, codes_list, temperature=None):\n        \"\"\"Fusionne le code original avec les propositions des agents\"\"\"\n        if not codes_list:\n            return original_code\n\n        # Construire un prompt pour le LLM\n        combined_prompt = \"Fusionne les modifications suivantes avec le code original :\\n\\n\"\n        for idx, c in enumerate(codes_list):\n            combined_prompt += f\"Modification {idx+1}:\\n{c}\\n\\n\"\n\n        if temperature is not None:\n            merged_code = self.llm.ask(\n                system_prompt=\"Tu es un assistant expert en refactoring de code. Fusionne les changements proposés en gardant le code fonctionnel et clair.\",\n                user_prompt=original_code + \"\\n\\n\" + combined_prompt,\n                temperature=temperature\n            )\n        else:\n            merged_code = self.llm.ask(\n                system_prompt=\"Tu es un assistant expert en refactoring de code. Fusionne les changements proposés en gardant le code fonctionnel et clair.\",\n                user_prompt=original_code + \"\\n\\n\" + c",
    "source": "agents/merge_agent.py"
  },
  {
    "id": "46ea4044724d831b",
    "text": "factoring de code. Fusionne les changements proposés en gardant le code fonctionnel et clair.\",\n                user_prompt=original_code + \"\\n\\n\" + combined_prompt\n            )\n\n        return merged_code",
    "source": "agents/merge_agent.py"
  },
  {
    "id": "344b6c645e90c41c",
    "text": "# ==================== agents/patch_agent.py (version corrigée) ====================\n\nfrom .base_agent import BaseAgent\nimport re\n\nclass PatchAgent(BaseAgent):\n    \"\"\"\n    Agent de nettoyage avancé avec validation de syntaxe.\n    \"\"\"\n    \n    def __init__(self, llm):\n        super().__init__(llm, name=\"PatchAgent\")\n        self.changes_applied = []\n    \n    def analyze(self, code, language):\n        \"\"\"Détecte les problèmes de formatage\"\"\"\n        issues = []\n        self.changes_applied = []  # Réinitialiser\n        \n        # Détection de markdown\n        if \"```\" in code:\n            issues.append({\"type\": \"markdown\", \"note\": \"Blocs Markdown détectés\"})\n        \n        # Détection de texte explicatif\n        lines = code.splitlines()\n        code_started = False\n        non_code_lines = []\n        \n        for i, line in enumerate(lines[:10]):  # Vérifier les 10 premières lignes\n            stripped = line.strip()\n            if not stripped:\n                continue\n            if not code_started:\n                if stripped.startswith((\"import\", \"def\", \"class\", \"from\", \"function\", \"public\", \"private\", \"const\", \"let\", \"var\")):\n                    code_started = True\n         ",
    "source": "agents/patch_agent.py"
  },
  {
    "id": "8a57c20d6ffcfccf",
    "text": "rtswith((\"import\", \"def\", \"class\", \"from\", \"function\", \"public\", \"private\", \"const\", \"let\", \"var\")):\n                    code_started = True\n                else:\n                    non_code_lines.append(f\"Ligne {i+1}: {stripped[:50]}...\")\n        \n        if non_code_lines:\n            issues.append({\"type\": \"explanatory_text\", \"note\": f\"Texte non-code détecté: {len(non_code_lines)} lignes\"})\n        \n        if not issues:\n            issues.append({\"type\": \"clean\", \"note\": \"Code relativement propre\"})\n        \n        return issues\n    \n    def clean_code(self, code, language):\n        \"\"\"\n        Nettoie le code sans utiliser le LLM pour éviter les erreurs de syntaxe.\n        Retourne uniquement du code syntaxiquement valide.\n        \"\"\"\n        cleaned_lines = []\n        in_code_block = False\n        \n        for line in code.splitlines():\n            stripped = line.strip()\n            \n            # Gestion des blocs markdown\n            if stripped.startswith(\"```\"):\n                in_code_block = not in_code_block\n                continue\n            \n            # Enlever le texte explicatif avant le code\n            if not in_code_block:\n                # Vérifier si c",
    "source": "agents/patch_agent.py"
  },
  {
    "id": "b1d3c04a0091b9cb",
    "text": "       continue\n            \n            # Enlever le texte explicatif avant le code\n            if not in_code_block:\n                # Vérifier si c'est une ligne de code valide\n                if (stripped.startswith((\"import\", \"from\", \"def\", \"class\", \"@\")) or\n                    (stripped and not stripped.startswith((\"# \", \"// \", \"/*\", \"* \")))):\n                    cleaned_lines.append(line)\n            else:\n                # À l'intérieur d'un bloc de code, tout garder\n                cleaned_lines.append(line)\n        \n        cleaned_code = \"\\n\".join(cleaned_lines)\n        \n        # Nettoyer les commentaires inline en excès (Python)\n        if language.lower() == \"python\":\n            lines = cleaned_code.splitlines()\n            cleaned_lines = []\n            for line in lines:\n                # Garder seulement jusqu'au premier # qui n'est pas dans une string\n                hash_pos = line.find(\"#\")\n                if hash_pos != -1:\n                    # Vérifier si le # est dans une string\n                    before_hash = line[:hash_pos]\n                    if before_hash.count('\"') % 2 == 0 and before_hash.count(\"'\") % 2 == 0:\n                        line = line[:ha",
    "source": "agents/patch_agent.py"
  },
  {
    "id": "c9fe537621e3e733",
    "text": " = line[:hash_pos]\n                    if before_hash.count('\"') % 2 == 0 and before_hash.count(\"'\") % 2 == 0:\n                        line = line[:hash_pos].rstrip()\n                if line.strip():  # Ne garder que les lignes non vides\n                    cleaned_lines.append(line)\n            cleaned_code = \"\\n\".join(cleaned_lines)\n        \n        return cleaned_code\n    \n    def apply(self, code, language, temperature=None):\n        \"\"\"Applique le nettoyage avec validation syntaxique\"\"\"\n        analysis = self.analyze(code, language)\n        self.changes_applied = []\n        \n        # Nettoyer le code (sans LLM pour éviter les erreurs)\n        cleaned_code = self.clean_code(code, language)\n        self.changes_applied.append(\"Texte explicatif et markdown supprimés\")\n        \n        # VALIDATION CRITIQUE : Vérifier la syntaxe Python\n        if language.lower() == \"python\":\n            try:\n                # Essayer de compiler le code\n                import ast\n                ast.parse(cleaned_code)\n                self.changes_applied.append(\"Syntaxe Python validée\")\n            except SyntaxError as e:\n                # En cas d'erreur, essayer de récupérer le code origina",
    "source": "agents/patch_agent.py"
  },
  {
    "id": "90a8f06bb89f7f77",
    "text": "_applied.append(\"Syntaxe Python validée\")\n            except SyntaxError as e:\n                # En cas d'erreur, essayer de récupérer le code original\n                print(f\"⚠️ Erreur de syntaxe après nettoyage: {e}\")\n                # Garder seulement les lignes qui semblent être du code Python\n                lines = cleaned_code.splitlines()\n                valid_lines = []\n                for line in lines:\n                    stripped = line.strip()\n                    if stripped and not stripped.startswith(\"# \"):\n                        valid_lines.append(line)\n                cleaned_code = \"\\n\".join(valid_lines)\n                self.changes_applied.append(f\"Erreur de syntaxe corrigée: {e}\")\n        \n        return {\n            \"name\": self.name,\n            \"analysis\": analysis,\n            \"proposal\": cleaned_code,\n            \"changes_applied\": self.changes_applied,\n            \"temperature_used\": temperature if temperature is not None else \"N/A\"\n        }",
    "source": "agents/patch_agent.py"
  },
  {
    "id": "27d283b9d23ae6ec",
    "text": "# agents/rename_agent.py - Version corrigée\n\nfrom agents.base_agent import BaseAgent\nimport re\n\nclass RenameAgent(BaseAgent):\n    \"\"\"\n    Agent spécialisé dans le renommage des variables pour améliorer la lisibilité.\n    \"\"\"\n    def __init__(self, llm):\n        super().__init__(llm, name=\"RenameAgent\")\n\n    def analyze(self, code, language):\n        \"\"\"\n        Trouve toutes les variables simples dans le code Python.\n        Pour d'autres langages, le prompt sera adapté automatiquement.\n        \"\"\"\n        if language == \"Python\":\n            # Regex pour trouver les noms de variables simples\n            pattern = r'\\b([a-zA-Z_][a-zA-Z0-9_]*)\\b'\n            tokens = set(re.findall(pattern, code))\n            # On filtre les mots-clés Python\n            keywords = {\n                \"def\",\"return\",\"if\",\"elif\",\"else\",\"for\",\"while\",\"in\",\"import\",\"from\",\"as\",\n                \"print\",\"break\",\"continue\",\"class\",\"with\",\"try\",\"except\",\"pass\",\"and\",\"or\",\"not\",\n                \"is\",\"lambda\",\"True\",\"False\",\"None\"\n            }\n            variables = [tok for tok in tokens if tok not in keywords]\n            return variables\n        else:\n            # Pour d'autres langages, on laisse le LLM ",
    "source": "agents/rename_agent.py"
  },
  {
    "id": "239a36130e53ba3b",
    "text": "es = [tok for tok in tokens if tok not in keywords]\n            return variables\n        else:\n            # Pour d'autres langages, on laisse le LLM analyser\n            return [\"LLM variable analysis needed\"]\n\n    def apply(self, code, language, temperature=None):\n        \"\"\"\n        Applique le renommage avec contrôle de température optionnel.\n        \n        Args:\n            code: Code source à analyser\n            language: Langage de programmation\n            temperature: Température pour le LLM (optionnel)\n        \"\"\"\n        analysis = self.analyze(code, language)\n        if analysis:\n            # Prompt très précis pour le renommage\n            prompt = (\n                f\"Refactor the following {language} code by renaming variables \"\n                f\"to meaningful names. Keep functionality unchanged. Variables: {analysis}\"\n            )\n            \n            # Appel LLM avec ou sans température\n            if temperature is not None:\n                proposal = self.llm.ask(\n                    system_prompt=prompt, \n                    user_prompt=code,\n                    temperature=temperature\n                )\n            else:\n                proposal = self.l",
    "source": "agents/rename_agent.py"
  },
  {
    "id": "334a8d478da10547",
    "text": "                   user_prompt=code,\n                    temperature=temperature\n                )\n            else:\n                proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)\n        else:\n            proposal = code\n        \n        return {\n            \"name\": self.name, \n            \"analysis\": analysis, \n            \"proposal\": proposal,\n            \"temperature_used\": temperature\n        }",
    "source": "agents/rename_agent.py"
  },
  {
    "id": "c1587b39f17d5475",
    "text": "# ==================== agents/test_agent.py (version améliorée) ====================\n\nfrom .base_agent import BaseAgent\nfrom pathlib import Path\nimport subprocess\nimport tempfile\nimport os\nimport sys\n\n\nclass StaticTools:\n    \"\"\"\n    Outils d'analyse statique avec gestion des erreurs d'installation.\n    \"\"\"\n    def __init__(self, repo_path: Path, language: str):\n        self.repo_path = repo_path\n        self.language = language.lower()\n        self.available_tools = self._detect_available_tools()\n\n    def _detect_available_tools(self):\n        \"\"\"Détecte les outils disponibles sur le système\"\"\"\n        available = {}\n        \n        # Vérifier les outils Python\n        python_tools = [\"ruff\", \"black\", \"mypy\", \"pylint\"]\n        for tool in python_tools:\n            try:\n                subprocess.run([tool, \"--version\"], \n                              capture_output=True, \n                              check=False)\n                available[tool] = True\n            except (FileNotFoundError, OSError):\n                available[tool] = False\n        \n        # Vérifier les compilateurs\n        compilers = {\n            \"python\": \"python\",\n            \"java\": \"javac\",\n            \"gc",
    "source": "agents/test_agent.py"
  },
  {
    "id": "2de3047241c40331",
    "text": " False\n        \n        # Vérifier les compilateurs\n        compilers = {\n            \"python\": \"python\",\n            \"java\": \"javac\",\n            \"gcc\": \"gcc\",\n            \"g++\": \"g++\",\n            \"go\": \"go\",\n            \"ruby\": \"ruby\",\n            \"node\": \"node\",\n            \"npm\": \"npm\"\n        }\n        \n        for name, cmd in compilers.items():\n            try:\n                subprocess.run([cmd, \"--version\"] if cmd != \"python\" else [cmd, \"--version\"],\n                              capture_output=True,\n                              check=False)\n                available[name] = True\n            except (FileNotFoundError, OSError):\n                available[name] = False\n        \n        return available\n\n    def run(self, cmd, tool_name=None):\n        \"\"\"\n        Exécute une commande avec gestion d'erreur améliorée.\n        \n        Returns:\n            tuple: (status_code, output, error_message)\n        \"\"\"\n        # Vérifier si l'outil est disponible\n        if tool_name and not self.available_tools.get(tool_name, False):\n            return -1, \"\", f\"Outil '{tool_name}' non disponible. Installez-le d'abord.\"\n        \n        try:\n            p = subprocess.run(\n         ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "55265be2b708235a",
    "text": "           return -1, \"\", f\"Outil '{tool_name}' non disponible. Installez-le d'abord.\"\n        \n        try:\n            p = subprocess.run(\n                cmd,\n                cwd=self.repo_path,\n                capture_output=True,\n                text=True,\n                encoding=\"utf-8\",\n                errors=\"ignore\"\n            )\n            output = (p.stdout or \"\") + \"\\n\" + (p.stderr or \"\")\n            return p.returncode, output.strip(), \"\"\n        except FileNotFoundError:\n            return -1, \"\", f\"Commande introuvable : {cmd[0]}\"\n        except Exception as e:\n            return -1, \"\", f\"Erreur d'exécution : {str(e)}\"\n\n    def python_syntax(self, filename):\n        \"\"\"Vérifie la syntaxe Python (toujours disponible)\"\"\"\n        return self.run([\"python\", \"-m\", \"py_compile\", filename], \"python\")\n\n    def ruff(self):\n        \"\"\"Exécute Ruff si disponible\"\"\"\n        if self.available_tools.get(\"ruff\", False):\n            return self.run([\"ruff\", \"check\", \".\", \"--exit-zero\"], \"ruff\")\n        return -1, \"\", \"Ruff non installé. Installez avec: pip install ruff\"\n\n    def black_check(self):\n        \"\"\"Vérifie le formatage avec Black si disponible\"\"\"\n        if self.availab",
    "source": "agents/test_agent.py"
  },
  {
    "id": "beed989e0366fce1",
    "text": "llé. Installez avec: pip install ruff\"\n\n    def black_check(self):\n        \"\"\"Vérifie le formatage avec Black si disponible\"\"\"\n        if self.available_tools.get(\"black\", False):\n            return self.run([\"black\", \"--check\", \".\"], \"black\")\n        return -1, \"\", \"Black non installé. Installez avec: pip install black\"\n\n    def mypy(self):\n        \"\"\"Vérification de types avec mypy si disponible\"\"\"\n        if self.available_tools.get(\"mypy\", False):\n            return self.run([\"mypy\", \".\"], \"mypy\")\n        return -1, \"\", \"mypy non installé. Installez avec: pip install mypy\"\n\n\nclass TestAgent(BaseAgent):\n    \"\"\"\n    Agent de validation avec gestion des outils manquants.\n    \"\"\"\n\n    def __init__(self, llm):\n        super().__init__(llm, name=\"TestAgent\")\n        self.supported_languages = {\n            \"python\": [\"python_syntax\", \"ruff\", \"black_check\", \"mypy\"],\n            \"javascript\": [],\n            \"typescript\": [],\n            \"java\": [],\n            \"c\": [],\n            \"cpp\": [],\n            \"go\": [],\n            \"ruby\": [],\n        }\n\n    def analyze(self, code, language):\n        \"\"\"\n        Analyse le code avec gestion élégante des outils manquants.\n        \"\"\"\n        ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "2d28faeb35765fd7",
    "text": "        }\n\n    def analyze(self, code, language):\n        \"\"\"\n        Analyse le code avec gestion élégante des outils manquants.\n        \"\"\"\n        lang_key = language.lower()\n        report = {\n            \"status\": \"SUCCESS\",\n            \"summary\": [],\n            \"details\": [],\n            \"warnings\": [],\n            \"metrics\": {},\n            \"tools_available\": True\n        }\n\n        with tempfile.TemporaryDirectory() as tmp:\n            path = Path(tmp)\n            \n            # Déterminer l'extension\n            extensions = {\n                \"python\": \".py\",\n                \"javascript\": \".js\", \n                \"typescript\": \".ts\",\n                \"java\": \".java\",\n                \"c\": \".c\",\n                \"cpp\": \".cpp\",\n                \"go\": \".go\",\n                \"ruby\": \".rb\"\n            }\n            \n            ext = extensions.get(lang_key, \".py\")\n            filename = f\"test_code{ext}\"\n            file_path = path / filename\n            \n            # Écrire le code\n            file_path.write_text(code, encoding=\"utf-8\")\n            \n            # Initialiser les outils\n            tools = StaticTools(path, language)\n            \n            # Vérification synt",
    "source": "agents/test_agent.py"
  },
  {
    "id": "3688a1bf7e2fe4d1",
    "text": "utf-8\")\n            \n            # Initialiser les outils\n            tools = StaticTools(path, language)\n            \n            # Vérification syntaxique BASIQUE (toujours disponible)\n            if lang_key == \"python\":\n                ret, out, err = tools.python_syntax(filename)\n                status = \"SUCCESS\" if ret == 0 else \"FAILED\"\n                detail = {\n                    \"tool\": \"python_syntax\",\n                    \"status\": status,\n                    \"return_code\": ret,\n                    \"output\": out or \"Syntaxe Python valide\",\n                    \"error\": err\n                }\n                \n                if err:\n                    detail[\"suggestion\"] = \"Utilisez 'python -m py_compile fichier.py' pour vérifier manuellement\"\n                \n                report[\"details\"].append(detail)\n                \n                if ret != 0:\n                    report[\"status\"] = \"FAILED\"\n                    report[\"summary\"].append(\"❌ Erreur de syntaxe Python détectée\")\n                    \n                    # Afficher l'erreur de syntaxe de manière lisible\n                    if out:\n                        error_lines = out.split(\"\\n\")\n                 ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "f0a0296c55e8f2a8",
    "text": " # Afficher l'erreur de syntaxe de manière lisible\n                    if out:\n                        error_lines = out.split(\"\\n\")\n                        for line in error_lines[:3]:  # Afficher seulement les 3 premières lignes\n                            if line.strip():\n                                report[\"summary\"].append(f\"   → {line.strip()}\")\n            \n            # Outils optionnels (avec gestion d'absence)\n            if lang_key == \"python\":\n                # Ruff\n                ret, out, err = tools.ruff()\n                if err and \"non installé\" in err:\n                    report[\"warnings\"].append(\"⚠️ Ruff non installé - impossible de vérifier le style\")\n                    report[\"tools_available\"] = False\n                else:\n                    status = \"SUCCESS\" if ret == 0 else \"WARNING\"\n                    report[\"details\"].append({\n                        \"tool\": \"ruff\",\n                        \"status\": status,\n                        \"return_code\": ret,\n                        \"output\": out or \"✅ Aucun problème de style détecté\",\n                        \"error\": err\n                    })\n                    if ret != 0:\n                        repo",
    "source": "agents/test_agent.py"
  },
  {
    "id": "6ce5def28291ab4c",
    "text": " problème de style détecté\",\n                        \"error\": err\n                    })\n                    if ret != 0:\n                        report[\"summary\"].append(\"⚠️ Problèmes de style détectés (Ruff)\")\n                        if report[\"status\"] == \"SUCCESS\":\n                            report[\"status\"] = \"WARNING\"\n                \n                # Black\n                ret, out, err = tools.black_check()\n                if err and \"non installé\" in err:\n                    report[\"warnings\"].append(\"⚠️ Black non installé - impossible de vérifier le formatage\")\n                else:\n                    status = \"SUCCESS\" if ret == 0 else \"WARNING\"\n                    report[\"details\"].append({\n                        \"tool\": \"black\",\n                        \"status\": status,\n                        \"return_code\": ret,\n                        \"output\": out or \"✅ Formatage correct (Black)\",\n                        \"error\": err\n                    })\n                    if ret != 0:\n                        report[\"warnings\"].append(\"Code nécessite un reformatage avec Black\")\n                \n                # mypy\n                ret, out, err = tools.mypy()\n               ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "f47fd6597cf1f84f",
    "text": "ppend(\"Code nécessite un reformatage avec Black\")\n                \n                # mypy\n                ret, out, err = tools.mypy()\n                if err and \"non installé\" in err:\n                    report[\"warnings\"].append(\"⚠️ mypy non installé - impossible de vérifier les types\")\n                else:\n                    status = \"SUCCESS\" if ret == 0 else \"WARNING\"\n                    report[\"details\"].append({\n                        \"tool\": \"mypy\",\n                        \"status\": status,\n                        \"return_code\": ret,\n                        \"output\": out or \"✅ Aucune erreur de type\",\n                        \"error\": err\n                    })\n                    if ret != 0:\n                        report[\"warnings\"].append(\"Problèmes de typage détectés\")\n            \n            # Calculer les métriques de base (toujours disponibles)\n            self._calculate_basic_metrics(code, report, lang_key)\n        \n        return report\n\n    def _calculate_basic_metrics(self, code, report, language):\n        \"\"\"Calcule les métriques de base sans outils externes\"\"\"\n        lines = code.splitlines()\n        non_empty_lines = [l for l in lines if l.strip()]\n      ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "5eceb9981a0278eb",
    "text": "lcule les métriques de base sans outils externes\"\"\"\n        lines = code.splitlines()\n        non_empty_lines = [l for l in lines if l.strip()]\n        \n        report[\"metrics\"] = {\n            \"total_lines\": len(lines),\n            \"non_empty_lines\": len(non_empty_lines),\n            \"characters\": len(code),\n            \"average_line_length\": sum(len(l) for l in lines) / max(1, len(lines))\n        }\n        \n        # Détecter les problèmes évidents\n        warnings = []\n        \n        # Lignes trop longues\n        long_lines = [i+1 for i, line in enumerate(lines) if len(line) > 120]\n        if long_lines:\n            warnings.append(f\"Lignes trop longues (>120 chars): {long_lines[:3]}\")\n        \n        # Indentation incohérente (Python)\n        if language == \"python\":\n            indent_sizes = set()\n            for line in non_empty_lines:\n                if line.strip():\n                    indent = len(line) - len(line.lstrip())\n                    if indent > 0:\n                        indent_sizes.add(indent)\n            \n            if len(indent_sizes) > 2:  # Plus de 2 tailles d'indentation différentes\n                warnings.append(\"Indentation incohérente détectée",
    "source": "agents/test_agent.py"
  },
  {
    "id": "d8cea48bc2c0f777",
    "text": "            if len(indent_sizes) > 2:  # Plus de 2 tailles d'indentation différentes\n                warnings.append(\"Indentation incohérente détectée\")\n        \n        if warnings:\n            report[\"warnings\"].extend(warnings)\n\n    def apply(self, code, language, temperature=None):\n        \"\"\"\n        Applique l'analyse avec correction automatique si erreurs de syntaxe.\n        \"\"\"\n        analysis = self.analyze(code, language)\n        \n        # Si erreur de syntaxe et LLM disponible, essayer de corriger\n        if analysis[\"status\"] == \"FAILED\" and hasattr(self.llm, 'ask'):\n            # Chercher les erreurs de syntaxe\n            syntax_errors = []\n            for detail in analysis.get(\"details\", []):\n                if detail.get(\"tool\") == \"python_syntax\" and detail.get(\"status\") == \"FAILED\":\n                    output = detail.get(\"output\", \"\")\n                    if output:\n                        # Extraire l'erreur de syntaxe\n                        lines = output.split(\"\\n\")\n                        for line in lines:\n                            if \"SyntaxError\" in line or \"Error\" in line:\n                                syntax_errors.append(line.strip())\n           ",
    "source": "agents/test_agent.py"
  },
  {
    "id": "d0b279cdfd206be6",
    "text": "                           if \"SyntaxError\" in line or \"Error\" in line:\n                                syntax_errors.append(line.strip())\n            \n            if syntax_errors:\n                try:\n                    print(f\"🔄 Tentative de correction de {len(syntax_errors)} erreur(s) de syntaxe...\")\n                    \n                    prompt = f\"\"\"\nLe code Python suivant a des erreurs de syntaxe. \nCorrige UNIQUEMENT les erreurs de syntaxe, ne change pas la logique.\nRetourne SEULEMENT le code Python corrigé.\n\nErreurs détectées:\n{chr(10).join(f'- {err}' for err in syntax_errors[:3])}\n\nCode avec erreurs:\n{code}\n\"\"\"\n                    \n                    corrected_code = self.llm.ask(\n                        system_prompt=\"Expert en correction de syntaxe Python. Ne change que ce qui est nécessaire pour corriger les erreurs de syntaxe.\",\n                        user_prompt=prompt,\n                        temperature=0.1  # Très bas pour la précision\n                    )\n                    \n                    # Nettoyer le code corrigé\n                    corrected_code = self._clean_llm_response(corrected_code)\n                    \n                    # Vérifier si le co",
    "source": "agents/test_agent.py"
  },
  {
    "id": "6f9ca7b9c40f1b73",
    "text": "ode corrigé\n                    corrected_code = self._clean_llm_response(corrected_code)\n                    \n                    # Vérifier si le code corrigé est différent\n                    if corrected_code and corrected_code != code:\n                        # Réanalyser\n                        corrected_analysis = self.analyze(corrected_code, language)\n                        if corrected_analysis[\"status\"] != \"FAILED\":\n                            code = corrected_code\n                            analysis = corrected_analysis\n                            analysis[\"summary\"].insert(0, \"✅ Erreurs de syntaxe corrigées automatiquement\")\n                            analysis[\"summary\"].append(\"🔧 Correction par LLM avec température=0.1\")\n                        else:\n                            analysis[\"summary\"].append(\"⚠️ Correction automatique échouée - erreurs persistantes\")\n                    \n                except Exception as e:\n                    print(f\"⚠️ Échec de la correction automatique: {e}\")\n                    analysis[\"summary\"].append(\"❌ Correction automatique impossible\")\n        \n        return {\n            \"name\": self.name,\n            \"status\": analysis.g",
    "source": "agents/test_agent.py"
  },
  {
    "id": "8a24fe032d512428",
    "text": "sis[\"summary\"].append(\"❌ Correction automatique impossible\")\n        \n        return {\n            \"name\": self.name,\n            \"status\": analysis.get(\"status\", \"N/A\"),\n            \"summary\": analysis.get(\"summary\", []),\n            \"details\": analysis.get(\"details\", []),\n            \"warnings\": analysis.get(\"warnings\", []),\n            \"metrics\": analysis.get(\"metrics\", {}),\n            \"tools_available\": analysis.get(\"tools_available\", True),\n            \"proposal\": code,\n            \"temperature_used\": temperature if temperature is not None else \"N/A\"\n        }\n    \n    def _clean_llm_response(self, response):\n        \"\"\"Nettoie la réponse du LLM pour extraire uniquement le code\"\"\"\n        # Supprimer les backticks\n        if \"```\" in response:\n            parts = response.split(\"```\")\n            if len(parts) >= 3:\n                # Prendre le contenu entre les premiers backticks\n                response = parts[1]\n                # Enlever le langage spécificateur\n                if response.startswith(\"python\\n\"):\n                    response = response[7:]\n        \n        # Supprimer le texte explicatif avant le code\n        lines = response.splitlines()\n        code_lin",
    "source": "agents/test_agent.py"
  },
  {
    "id": "56b211f139303b1a",
    "text": "         response = response[7:]\n        \n        # Supprimer le texte explicatif avant le code\n        lines = response.splitlines()\n        code_lines = []\n        code_started = False\n        \n        for line in lines:\n            stripped = line.strip()\n            if not code_started:\n                if stripped.startswith((\"import\", \"def\", \"class\", \"from\", \"@\")):\n                    code_started = True\n                    code_lines.append(line)\n                elif stripped and not stripped.startswith((\"# \", \"// \")):\n                    # Si c'est du code sans mot-clé évident\n                    code_started = True\n                    code_lines.append(line)\n            else:\n                code_lines.append(line)\n        \n        return \"\\n\".join(code_lines) if code_lines else response",
    "source": "agents/test_agent.py"
  },
  {
    "id": "b8c7984e23bcae51",
    "text": "# ==================== agents/__init__.py ====================\n# Fichier d'initialisation du module agents\n\nfrom .base_agent import BaseAgent\nfrom .rename_agent import RenameAgent\nfrom .complexity_agent import ComplexityAgent\nfrom .duplication_agent import DuplicationAgent\nfrom .import_agent import ImportAgent\nfrom .long_function_agent import LongFunctionAgent\nfrom .merge_agent import MergeAgent\nfrom .patch_agent import PatchAgent\nfrom .test_agent import TestAgent\n\n__all__ = [\n    \"BaseAgent\",\n    \"RenameAgent\", \n    \"ComplexityAgent\",\n    \"DuplicationAgent\",\n    \"ImportAgent\",\n    \"LongFunctionAgent\",\n    \"MergeAgent\",\n    \"PatchAgent\",\n    \"TestAgent\"\n]",
    "source": "agents/__init__.py"
  }
]