# agents/base_agent.py

from __future__ import annotations

import inspect

# GraphRAG: import optionnel (fallback si le module n'existe pas)
try:
    from core.graphrag_retriever import GraphRAGRetriever
except Exception:
    GraphRAGRetriever = None


class BaseAgent:
    """
    Classe de base pour tous les agents avec support de temp√©rature r√©trocompatible
    + GraphRAG (optionnel) pour enrichir le contexte.

    GraphRAG est activ√© uniquement pour les agents de refactoring structurel/s√©mantique.
    """

    # ‚úÖ RAG seulement pour ces 5 agents
    GRAPHRAG_ENABLED_AGENTS = {
        "RenameAgent",
        "ComplexityAgent",
        "DuplicationAgent",
        "ImportAgent",
        "LongFunctionAgent",
    }

    def __init__(self, llm, name: str = "Agent inconnu", use_graphrag: bool = True):
        self.llm = llm
        self.name = name
        self.use_graphrag = use_graphrag

    def analyze(self, code, language):
        """
        Analyse le code et retourne une liste de probl√®mes ou suggestions.
        Doit √™tre surcharg√©e par chaque agent.
        """
        return []

    def build_prompt(self, code, language):
        """M√©thode par d√©faut pour construire le prompt (peut √™tre surcharg√©e)"""
        return f"Refactor the following {language} code for {self.name} improvements."

    def _should_use_graphrag(self) -> bool:
        """
        D√©cide automatiquement si GraphRAG doit √™tre utilis√© pour cet agent.
        """
        return (
            self.use_graphrag
            and self.name in self.GRAPHRAG_ENABLED_AGENTS
            and GraphRAGRetriever is not None
        )

    def _inject_graphrag(self, system_prompt: str, code: str, language: str) -> str:
        """
        Injecte un contexte GraphRAG dans le prompt syst√®me.
        Si GraphRAG n'est pas disponible, non autoris√© pour cet agent, ou √©choue,
        retourne system_prompt inchang√©.
        """
        if not self._should_use_graphrag():
            return system_prompt

        try:
            retriever = GraphRAGRetriever()
            query = (
                f"Refactoring context for agent={self.name}, language={language}. "
                f"Project conventions, related modules/classes/functions, dependencies. "
                f"Code snippet: {code[:600]}"
            )

            pack = retriever.retrieve(query=query, k_seeds=4, hops=2, max_chunks=6)
            context_txt = retriever.format_context(pack).strip()

            if not context_txt:
                return system_prompt

            # Debug utile (tu peux le garder)
            print(f"üîé GraphRAG inject√© pour {self.name}")

            return (
                system_prompt
                + "\n\n"
                + context_txt
                + "\n\n"
                + "### Usage Rules\n"
                + "- Use retrieved context ONLY if relevant.\n"
                + "- Preserve exact behavior and public APIs.\n"
                + "- If context conflicts with code semantics, prefer code semantics.\n"
            )
        except Exception as e:
            # Fallback silencieux (mais log l√©ger utile pour debug)
            print(f"‚ö†Ô∏è GraphRAG ignor√© pour {self.name}: {e}")
            return system_prompt

    def apply(self, code, language, temperature=None):
        """
        Applique l'analyse sur le code.

        Args:
            code: Code source
            language: Langage de programmation
            temperature: Temp√©rature LLM (optionnel, r√©trocompatible)

        Returns:
            dict: R√©sultat standardis√©
        """
        analysis = self.analyze(code, language)

        if analysis:
            # V√©rifier si la m√©thode llm.ask supporte temperature
            llm_method = getattr(self.llm, "ask", None)
            if not callable(llm_method):
                raise AttributeError(f"LLM client {self.llm} n'a pas de m√©thode 'ask'")

            # Construire le prompt (peut √™tre surcharg√©)
            prompt = self.build_prompt(code, language)

            # ‚úÖ Injecter GraphRAG seulement pour les agents autoris√©s
            prompt = self._inject_graphrag(prompt, code, language)

            try:
                # Essayer d'appeler avec temp√©rature si support√©
                if temperature is not None:
                    sig = inspect.signature(self.llm.ask)
                    params = sig.parameters

                    if "temperature" in params:
                        proposal = self.llm.ask(
                            system_prompt=prompt,
                            user_prompt=code,
                            temperature=temperature
                        )
                    else:
                        # Fallback sans temp√©rature
                        proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)
                else:
                    proposal = self.llm.ask(system_prompt=prompt, user_prompt=code)

            except Exception as e:
                print(f"‚ö†Ô∏è Erreur LLM pour {self.name}: {e}")
                proposal = code
        else:
            proposal = code

        result = {
            "name": self.name,
            "analysis": analysis,
            "proposal": proposal
        }

        if temperature is not None:
            result["temperature_used"] = temperature

        return result